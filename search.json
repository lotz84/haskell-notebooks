[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "IHaskellで書いたnotebookを公開する場所\nZennにも記事を書いています\nhttps://zenn.dev/lotz"
  },
  {
    "objectID": "posts/2020-07-11/index.html",
    "href": "posts/2020-07-11/index.html",
    "title": "高次元空間ではL1距離を使うのが良さそう",
    "section": "",
    "text": "“On the Surprising Behavior of Distance Metrics in High Dimensional Spaces”という論文を読んで面白かったのでまとめておきます。\n\\(d\\)次元空間の立方体\\((0,1)^d\\)中に分布する確率変数\\(X_d\\)を考えます。例えばモノクロ画像なんかは正規化すれば今考えてる確率変数になるでしょう。今\\((0, 1)\\)上の任意の分布\\(F\\)を考え\\(F^d\\)を確率分布とする\\(X_d\\)から\\(n\\)個のサンプルが得られたとします。サンプルにおける\\(L_k\\)ノルムの最大値を\\(Dmax^k_d\\)、最小値を\\(Dmin^k_d\\)とすると、\\(F\\)と\\(k\\)のみに依存する定数\\(C_k\\)が存在して\n\\[\nC_k \\leq \\underset{d \\rightarrow \\infty}{\\lim}{\\rm E}\\left[\\frac{Dmax^k_d - Dmin^k_d}{d^{\\frac{1}{k}-\\frac{1}{2}}}\\right] \\leq (n-1)C_k\n\\]\nが成り立ちます。ここで\\({\\rm E}[X]\\)は\\(X\\)の期待値を表します。\nつまりデータの存在する次元が上がるにつれて原点に近いものと遠いものの差が変化するスピードは\\(d^{\\frac{1}{k}-\\frac{1}{2}}\\)ぐらいになるということです。証明を読めば分かりますが、差の漸近的な振る舞いを決める\\(d^{\\frac{1}{k}-\\frac{1}{2}}\\)の\\(\\frac{1}{2}\\)は中心極限定理から出てきます。もし\\(k \\geq 3\\)であればこれは減衰するので、どんどん近いデータと遠いデータの間に差がなくなってくるということを意味しています。これは原点を任意の注目する点に置き換えて考えれば、例えばサンプルの近傍を考えるときに次元が高くなると遠いものと近いものの区別がどんどんつかなくなっていくことを表しています。一方もし\\(k=2\\)であればこの差は一定に落ち着き、\\(k=1\\)であれば（期待通り？）大きくなってくれます。\n次元が高くなれば立方体の対角線の長さも大きくなるので直感的には最大値と最小値の差はどんどん大きくなっていきそうですが、同時に、すべての次元で0付近の値が出る確率や1付近の値が出る確率は次元が高くなるとどんどん小さくなるので、差の期待値がどう振る舞うかはこれらの綱引きになりそうなことは直感的には分かります。この綱引きの勝敗が距離の測り方で決まるのは面白いですね。\nこの挙動を実際に確かめてみましょう。\n\nimport Control.Monad (replicateM)\nimport System.Random.MWC\n\n\n-- | 確率変数\ntype RVar a = GenIO -&gt; IO a\n\n\n-- | n個のリストの確率変数\nrandomNs :: Int -&gt; RVar a -&gt; RVar [a]\nrandomNs n x = sample n\n  where\n    sample 0 _ = pure []\n    sample n g = do\n      a &lt;- x g\n      as &lt;- sample (n-1) g\n      pure (a:as)\n\n\n-- L_kノルム\nlk :: Int -&gt; [Double] -&gt; Double\nlk k xs = sum (map (^k) xs) ** (1.0 / fromIntegral k)\n\n\n-- | Dmax^k_d - Dmin^k_d\ndiameter :: Int -- 直径計算のためのサンプルを生成する数\n         -&gt; Int -- L_kノルムのk\n         -&gt; Int -- 次元d\n         -&gt; RVar Double\ndiameter n k d g =\n  let xs g = replicateM d (uniformR (0.0, 1.0) g)\n   in do\n     xss &lt;- randomNs n xs g\n     let ds = map (lk k) xss\n     pure $ maximum ds - minimum ds\n\n\n-- | 確率変数の期待値\nexpected :: Fractional a\n         =&gt; Int    -- 期待値を計算するのに用いるサンプル数\n         -&gt; RVar a -- 期待値を求める確率変数\n         -&gt; RVar a -- 期待値の確率変数\nexpected n x g = do\n  as &lt;- randomNs n x g\n  pure $ sum as / fromIntegral n\n\n\nimport Data.Traversable (forM)\nimport Graphics.Rendering.Chart.Easy\n\nds :: [Int]\nds = [1..50]\n\nwithSystemRandom $ \\gen -&gt; do\n  diff1 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 1 d) gen\n  diff2 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 2 d) gen\n  diff3 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 3 d) gen\n  diff4 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 4 d) gen\n  pure . toRenderable $ do\n      plot (line \"k = 1\" [zip ds diff1])\n      plot (line \"k = 2\" [zip ds diff2])\n      plot (line \"k = 3\" [zip ds diff3])\n      plot (line \"k = 4\" [zip ds diff4])\n\n\n\n\n\n\n\n\n次元を増やすにつれて\\(k=1\\)の時は最小値と最大値の差が大きくなっていきますが、\\(k=2\\)の場合は一定に落ち着き、\\(k=3,4\\)の場合は差がどんどんなくなっていき、この傾向は\\(k\\)が大きければより強いことが分かります。\n論文ではもう一つ面白い式が導かれています。先程の不等式は最大値と最小値の差についてでしたが、今度は比についてです。\n\\[\n\\underset{d \\rightarrow \\infty}{\\lim} {\\rm E}\\left[\\sqrt{d}\\left(\\frac{Dmax^k_d}{Dmin^k_d} - 1\\right)\\right] = C\\sqrt{\\frac{1}{2k+1}}\n\\]\nただしこの式は\\(F\\)が一様分布でサンプルが2点である時という制約がついています。この式が示唆するのは最大値と最小値の比は\\(\\frac{1}{\\sqrt{d}}\\)ぐらいのスピードで1に近づいていくということで、この挙動は\\(k\\)が1,2のときでも変わりません。"
  },
  {
    "objectID": "posts/2020-06-29/index.html",
    "href": "posts/2020-06-29/index.html",
    "title": "Haskellの非同期処理を使った入出力の重ね合わせ",
    "section": "",
    "text": "これは『Haskellによる並列・並行プログラミング』リモート輪講 #10の発表資料です。\nHaskellの非同期処理を使って並行に入出力を伴う処理を行うプログラムを書く方法について見ていきます。まず、複数のWebページを並行にダウンロードするようなタスクを考えます\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls1.hs\n\nimport Control.Concurrent\nimport Data.ByteString.Char8 as B\nimport System.Random\n\ngetURL :: String -&gt; IO ByteString\ngetURL url = do\n  delay &lt;- randomRIO (500000, 1500000) -- URLのコンテンツを取得する時間ということにする\n  threadDelay delay\n  pure (B.pack url)\n\nexample1 :: IO ()\nexample1 = do\n  m1 &lt;- newEmptyMVar\n  m2 &lt;- newEmptyMVar\n  \n  forkIO $ do\n    r &lt;- getURL \"https://en.wikipedia.org/wiki/Shovel\"\n    putMVar m1 r\n\n  forkIO $ do\n    r &lt;- getURL \"https://en.wikipedia.org/wiki/Spade\"\n    putMVar m2 r\n\n  r1 &lt;- takeMVar m1\n  r2 &lt;- takeMVar m2\n  print (B.length r1, B.length r2)\nという共通する実装のパターンが見え隠れしているので共通化してみましょう\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls2.hs\n\nnewtype Async a = Async (MVar a)\n\nasync :: IO a -&gt; IO (Async a)\nasync action = do\n  var &lt;- newEmptyMVar\n  forkIO (action &gt;&gt;= putMVar var)\n  pure (Async var)\n\nwait :: Async a -&gt; IO a\nwait (Async var) = readMVar var\n意図しないデッドロックを防ぐために wait では takeMVar ではなく readMVar を使っています\nこれを使えば example1 を以下のように書き換えることができます\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls2.hs\n\nexample2 :: IO ()\nexample2 = do\n  a1 &lt;- async (getURL \"https://en.wikipedia.org/wiki/Shovel\")\n  a2 &lt;- async (getURL \"https://en.wikipedia.org/wiki/Spade\")\n  r1 &lt;- wait a1\n  r2 &lt;- wait a2\n  print (B.length r1, B.length r2)\n\nexample2\n\n(36,35)\nモナディックなコンビネータを使って更に簡潔に書くことも可能です\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls3.hs\n\nsites =\n  [ \"http://www.google.com\"\n  , \"http://www.bing.com\"\n  , \"http://www.yahoo.com\"\n  , \"http://www.wikipedia.com/wiki/Spade\"\n  , \"http://www.wikipedia.com/wiki/Shovel\"\n  ]\n\nexample3 :: IO ()\nexample3 = do\n  as &lt;- mapM (async . getURL) sites\n  result &lt;- mapM wait as\n  print $ fmap B.length result\n\nexample3\n\n[21,19,20,35,36]"
  },
  {
    "objectID": "posts/2020-06-29/index.html#asyncでのエラー処理",
    "href": "posts/2020-06-29/index.html#asyncでのエラー処理",
    "title": "Haskellの非同期処理を使った入出力の重ね合わせ",
    "section": "Asyncでのエラー処理",
    "text": "Asyncでのエラー処理\ngetURL の中でエラーが起こった場合の挙動を見てみましょう\n\nimport Control.Exception\n\ngetURL' :: String -&gt; IO ByteString\ngetURL' url = do\n  throwIO (ErrorCall \"oops!\")\n  pure (B.pack url)\n\nexample4 :: IO ()\nexample4 = do\n  as &lt;- mapM (async . getURL') sites\n  result &lt;- mapM wait as\n  print $ fmap B.length result\n\nexample4\n\n: \nthread blocked indefinitely in an MVar operation\n\n\ngetURL' では async の中で putMVar が実行される前に例外が投げられてしまうので wait における readMVar が永遠にスレッドをブロックしてしまいます\nこれを安全な挙動に変えるために Async 周りの実装を修正してみしましょう\n\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls4.hs\n\nnewtype Async a = Async (MVar (Either SomeException a))\n\nasync :: IO a -&gt; IO (Async a)\nasync action = do\n  var &lt;- newEmptyMVar\n  forkIO (try action &gt;&gt;= putMVar var)\n  pure (Async var)\n\nwaitCatch :: Async a -&gt; IO (Either SomeException a)\nwaitCatch (Async var) = readMVar var\n\nwait :: Async a -&gt; IO a\nwait a = do\n  r &lt;- waitCatch a\n  case r of\n    Left e  -&gt; throwIO e\n    Right a -&gt; pure a\n\nasync と wait は以前のものと同じ型ですが、例外を適切に伝搬する仕組みを備えています\n\nexample5 :: IO ()\nexample5 = do\n  as &lt;- mapM (async . getURL') sites\n  result &lt;- mapM wait as\n  print $ fmap B.length result\n\nexample5\n\n: \noops!\n\n\n最初に非同期処理が例外を投げた時点でプログラム全体が停止しているのが分かります"
  },
  {
    "objectID": "posts/2020-06-29/index.html#非同期処理の合流",
    "href": "posts/2020-06-29/index.html#非同期処理の合流",
    "title": "Haskellの非同期処理を使った入出力の重ね合わせ",
    "section": "非同期処理の合流",
    "text": "非同期処理の合流\nここでは並行に実行している非同期処理のどれか一つでも結果を返した時点で何らかの処理を行いたいような場合について見ていきます。\n以下の例は並行に複数のWebサイトをダウンロードして\n\n最初にダウンロードが完了したWebサイトの情報を表示する\n残りのダウンロードが完了するのを待つ\n\nという挙動を実装しています。\n\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls5.hs\n\nimport Control.Monad\n\nexample6 :: IO ()\nexample6 = do\n  m &lt;- newEmptyMVar\n  let download url = do\n        r &lt;- getURL url\n        putMVar m (url, r)\n\n  mapM_ (forkIO . download) sites\n  \n  (url, r) &lt;- takeMVar m\n  print $ url ++ \": \" ++ show (B.length r)\n  replicateM_ 4 (takeMVar m)\n\n-- 実行するたびに結果が変わる\nexample6\n\n\"http://www.wikipedia.com/wiki/Shovel: 36\"\n\n\nこれを明示的に MVar を用いずに Async を使って実装する事を考えましょう。\n以下の waitEither は2つの Async を受け取って最初に完了した値を IO で返す関数です。\n\nwaitEither :: Async a -&gt; Async b -&gt; IO (Either a b)\nwaitEither a b = do\n  m &lt;- newEmptyMVar\n  forkIO $ try (fmap Left  (wait a)) &gt;&gt;= putMVar m\n  forkIO $ try (fmap Right (wait b)) &gt;&gt;= putMVar m\n  wait (Async m)\n\nこの仕組は複数の Async のリストにも拡張することができます\n\nwaitAny :: [Async a] -&gt; IO a\nwaitAny as = do\n  m &lt;- newEmptyMVar\n  let forkwait a = forkIO $ try (wait a) &gt;&gt;= putMVar m\n  mapM_ forkwait as\n  wait (Async m)\n\n\n-- 勉強会中に逆に全てのAsyncを待つようなコンビネータが作れるか？という質問があったので実装してみた例\nwaitAll :: [Async a] -&gt; IO [a]\nwaitAll = mapM wait\n\n以上の実装を使って example6 は明示的に MVar を使わない形で書き換えることができます。\n\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls6.hs\n\nexample7 :: IO ()\nexample7 = do\n  let download url = do\n        r &lt;- getURL url\n        pure (url, r)\n\n  as &lt;- mapM (async . download) sites\n  \n  (url, r) &lt;- waitAny as\n  \n  print $ url ++ \": \" ++ show (B.length r)\n  mapM_ wait as\n\nexample7\n\n\"http://www.wikipedia.com/wiki/Spade: 35\""
  },
  {
    "objectID": "posts/2020-04-12/index.html",
    "href": "posts/2020-04-12/index.html",
    "title": "GHCi の :sprint が便利",
    "section": "",
    "text": "これは『Haskellによる並列・並行プログラミング』リモート輪講 #1で学んだことのメモです。\n:sprintは変数の評価を”行わずに”その内容を表示する機能。これを使えばサンクのまま詰まれていてまだ評価されていない部分も確認することができる\n\nlet x = 1 + 2 :: Int\n\n:sprint x\n\nx = _\n\n\n\n↑アンダースコアはサンクを表しておりxがまだ評価されていないことが分かる\n\nx\n\n:sprint x\n\n3\n\n\nx = 3\n\n\n\n↑xが評価されたので中身も見えるようになった\n次は変数が変数を参照している例\n\nx = 1 + 2 :: Int\ny = x + 1\n\n:sprint x\n:sprint y\n\nx = _\n\n\n\ny = _\n\n\n\n\nseq y ()\n\n:sprint x\n:sprint y\n\n()\n\n\nx = 3\n\n\n\ny = 4\n\n\n\n↑seqを使うと第一引数が弱頭部正規形（最初の構成子が見えるところ）まで強制的に評価される\n\nx = 1 + 2 :: Int\nz = (x, x)\n\n:sprint z\n\nz = _\n\n\n\nあれ？これはへいへいHaskellでは z = (_, _) と見えるはずなんだけど違う結果になってしまった。\n\nimport Data.Tuple\n\nz = swap (x, x + 1)\n\n:sprint z\n\nz = _\n\n\n\n\nseq z ()\n\n:sprint z\n\n()\n\n\nz = (_,_)\n\n\n\n↑今度はうまくタプルの構成子が見えるところまで評価された\n\nseq x ()\n\n:sprint z\n\n()\n\n\nz = (_,3)\n\n\n\n↑xだけ評価すると3が見えるようになった。zが評価されていないのでx + 1の部分はサンク_のままである\n今度はリストと map を使ったときの挙動を見てみる\n\nxs = map (+1) [1..10] :: [Int]\n\n:sprint xs\n\nxs = _\n\n\n\n\nseq xs ()\n\n:sprint xs\n\n()\n\n\nxs = _ : _\n\n\n\n↑:はリストの構成子なのでここが弱頭部正規形\n\nlength xs\n\n:sprint xs\n\n10\n\n\nxs = [_,_,_,_,_,_,_,_,_,_]\n\n\n\n↑lengthは中身を評価しないので構造だけが評価されて中はサンクのまま\n\nsum xs\n\n:sprint xs\n\n65\n\n\nxs = [2,3,4,5,6,7,8,9,10,11]\n\n\n\n↑これで全部評価された\n:sprint を使うとHaskellの遅延評価で何がどこまで評価されるのかインタラクティブに分かるので面白い。"
  },
  {
    "objectID": "posts/2024-09-26/index.html",
    "href": "posts/2024-09-26/index.html",
    "title": "ランダムフィボナッチ数列をHaskellで実装する",
    "section": "",
    "text": "ランダムフィボナッチ数列というフィボナッチ数列の計算にランダム要素を取り入れた数列があります。通常のフィボナッチ数列は \\(x_0 = 1, x_1 = 1\\) から始まり\n\\[\nx_n = x_{n-1} + x_{n-2}\n\\]\nという漸化式で値が定まりますが、ランダムフィボナッチ数列は初項は同じで漸化式が\n\\[\nx_n = \\begin{cases} x_{n-1} + x_{n-2} \\\\ x_{n-1} - x_{n-2} \\end{cases}\n\\]\nとなり±どちらになるかは各項において確率 \\(\\frac{1}{2}\\) でランダムに決まります。\nこのランダムフィボナッチ数列には面白い性質が知られていて、数列の増大速度の割合が\n\\[\n\\lim_{n\\rightarrow\\infty}\\sqrt[n]{|x_n|} = 1.1319882487943\\dots\n\\]\nと一定の値に収束する確率が1となるのです。この値はViswanath定数と呼ばれフラクタル測度を使った積分による解析的な表示が知られているようです（ちなみに通常のフィボナッチ数列の場合、この値は黄金比になります）。\n今回はこのランダムフィボナッチ数列を実装しViswanath定数をシミュレーションにより計算してみたいと思います。"
  },
  {
    "objectID": "posts/2024-09-26/index.html#ランダムフィボナッチ数列の実装",
    "href": "posts/2024-09-26/index.html#ランダムフィボナッチ数列の実装",
    "title": "ランダムフィボナッチ数列をHaskellで実装する",
    "section": "ランダムフィボナッチ数列の実装",
    "text": "ランダムフィボナッチ数列の実装\nまずは通常のフィボナッチ数列の実装を思い出しましょう。Haskellによるフィボナッチ数列の実装は様々ありますが、例えば以下のような方法が有名でしょう。\n\nfibs :: [Integer]\nfibs = map fib [0..]\n\nfib :: Int -&gt; Integer\nfib 0 = 1\nfib 1 = 1\nfib n = fibs !! (n-2) + fibs !! (n-1)\n\n\ntake 10 fibs\n\n[1,1,2,3,5,8,13,21,34,55]\n\n\nこちらに実装の動作の様子を表すアニメーションもあります。\nまずはこれを参考にランダムフィボナッチ数列を計算する実装を書いてみましょう。\n\nimport System.Random (randomIO)\n\nrfibs1 :: IO [Integer]\nrfibs1 = mapM rfib1 [0..]\n\nrfib1 :: Int -&gt; IO Integer\nrfib1 0 = pure 1\nrfib1 1 = pure 1\nrfib1 n = do\n  x &lt;- (!! (n-2)) &lt;$&gt; rfibs1\n  y &lt;- (!! (n-1)) &lt;$&gt; rfibs1\n  b &lt;- randomIO\n  pure $ if b\n    then x + y\n    else x - y\n\n\n-- &gt; take 10 &lt;$&gt; rfibs1\n-- 何も表示されず動作は終了しない\n\nこちらのナイーブな実装だと実行しても動作は終了しません。なぜでしょうか？\nこれは Lazy I/O を避けるため IO 型が正格評価を行っているからで、簡単に言えば fibs の場合と異なり IO [Integer] からは遅延評価でリストの必要な部分だけを取り出すことはできず、中身を見るにはまず無限リストを評価しないといけない状況になっているのです。\n単純な解決方法としては unsafeInterleaveIO を使用して遅延評価版の mapM を定義するというものがありますが、unsafeな方法に頼るのは避けたいです。もちろん関数に必要な数列の長さも与えればこの問題を回避して実装することができますが、“無限の数列”と”必要な分だけ値を取り出す処理”の2つに分離して組み合わせる方が、実装を簡潔に保つことができるでしょう。ですので乱数が絡む数列であっても遅延評価をうまく使える無限列を定義できないか考えてみたいと思います。\n\nListT\n遅延評価と IO を組み合わせたいと思ったときの解決策として pipes や conduit のようなストリーム処理をサポートするライブラリの活用が挙げられます。今回はその中でも基本的な list-t を使うことにしましょう。ListT は名前の通りリストをモナドトランスフォーマーに拡張したものになっています。\nnewtype ListT m a = ListT (m (Maybe (a, ListT m a)))\nなぜ ListT の定義が単純な m [a] ではなくこのような実装になっているかは面白い話なのですが、既に分かりやすい解説記事があるので気になる人は下記を参照してみてください。\n\n随伴から作られるMonad\nいろいろなパッケージから提供されている ListT モナド変換子の違いについて調べてみる\nListT done right\n\n早速 ListT を使ったランダムフィボナッチ数列の実装を考えてみましょう。\n\nimport ListT (ListT)\nimport qualified ListT\n\nrfibs2 :: ListT IO Integer\nrfibs2 = ListT.traverse rfib2 $ ListT.fromFoldable [0..]\n\nrfib2 :: Int -&gt; IO Integer\nrfib2 0 = pure 1\nrfib2 1 = pure 1\nrfib2 n = do\n  (fs, _) &lt;- ListT.splitAt n rfibs2\n  let x = fs !! (n-2)\n      y = fs !! (n-1)\n  b &lt;- randomIO :: IO Bool\n  pure $ if b\n    then x + y\n    else x - y\n\n\nListT.toList $ ListT.take 10 rfibs2\n\n[1,1,2,3,1,-2,-1,-1,-4,-5]\n\n\n今度は動きました！しかし待ってください。よく見ると各項がバラバラで前2つの項の和や差に一致しておらずランダムフィボナッチ数列になっていません。これは rfibs2 の要素はアクションであり計算結果がメモ化されるわけではないので rfib2 の中で rfibs2 が呼ばれる際に各項がまた再計算されてしまい起こっているのです。それなら仕方がないので数列全体をメモ化する方法は諦めて必要な項の値を引き回す実装に変えましょう。\n\nrfibs :: ListT IO Integer\nrfibs = flip ListT.unfoldM (1, 1) $ \\(x, y) -&gt; do\n  b &lt;- randomIO\n  pure (Just (x, (y, if b then x+y else x-y)))\n\n\nListT.toList $ ListT.take 10 rfibs\n\n[1,1,2,-1,1,0,1,-1,2,1]\n\n\n\nListT.toList $ ListT.take 100 rfibs\n\n[1,1,0,1,1,2,3,-1,4,3,1,4,5,-1,4,3,1,4,-3,7,4,3,7,10,17,-7,10,3,13,16,-3,13,-16,29,-45,-16,-29,-45,-74,29,-103,132,-235,-103,-132,-235,-367,-602,-969,-1571,602,-2173,2775,602,2173,2775,4948,7723,12671,-4948,7723,-12671,20394,-33065,53459,-86524,-33065,-119589,86524,-206113,-119589,-325702,206113,-531815,-325702,-857517,-1183219,325702,-857517,1183219,-2040736,3223955,-5264691,8488646,3223955,5264691,8488646,-3223955,11712601,8488646,20201247,28689893,48891140,77581033,-28689893,48891140,-77581033,-28689893,-106270926,77581033]\n\n\n今度はちゃんと動いてますね！"
  },
  {
    "objectID": "posts/2024-09-26/index.html#viswanath定数の計算",
    "href": "posts/2024-09-26/index.html#viswanath定数の計算",
    "title": "ランダムフィボナッチ数列をHaskellで実装する",
    "section": "Viswanath定数の計算",
    "text": "Viswanath定数の計算\nそれでは実装したランダムフィボナッチ数列 rfibs を使ってViswanath定数を計算してみましょう。まずは最初の20個ほど計算して眺めてみます。\n\ndo\n  xs &lt;- ListT.toList $ ListT.take 20 rfibs\n  mapM_ print $ zipWith (\\n x -&gt; abs (fromIntegral x) ** (1/n)) [0..] xs\n\n1.0\n1.0\n1.4142135623730951\n1.4422495703074083\n1.4953487812212205\n1.5157165665103982\n1.2009369551760027\n1.4085438884286994\n1.390804235062458\n1.4299691483087287\n1.4424689075546286\n1.271140212359713\n1.3921616171717222\n1.3818703308868108\n1.4077091909894845\n1.3030219289284708\n1.3005578511750604\n1.1679366751416516\n1.2467894073120835\n1.247697199056454\n\n\nうまく計算できていそうですね！（n=0のところは \\(1^\\infty = 1\\) ）\n最後により大きな項まで計算して定数に収束していく様子を眺めて終わりましょう。\n\nimport Graphics.Rendering.Chart.Easy\n\ndo\n  xs &lt;- ListT.toList $ ListT.take 3000 rfibs\n  let cs = zipWith (\\n x -&gt; abs (fromIntegral x) ** (1/n)) [0..] xs\n  pure . toRenderable $ do  \n    layout_title .= (\"last cs = \" ++ show (last cs))\n    plot (line \"\" [zip [0..] cs])"
  },
  {
    "objectID": "posts/2024-10-20/index.html",
    "href": "posts/2024-10-20/index.html",
    "title": "微分可能な比較演算子でライフゲームを逆算する",
    "section": "",
    "text": "“Conway’s Gradient of Life” という記事に、ライフゲームを逆算する手法について書かれており、面白かったので私も自分で試してみることにしました。ライフゲームは、セル・オートマトンと呼ばれる2次元のグリッド上で動作するシミュレーションで、各セルは隣接するセルの状態に応じて次のステップでの生死の状態が決定します。ライフゲームを「逆算する」とは、ある特定のパターンに至る前の状態を推定することを意味します。つまり、1ステップ進めるとある形に収束する状態を、その形から逆に探し出す課題です。\n今回は、ライフゲームのルールに基づいて1ステップ進めた時に、私のアイコンが現れるような初期状態を求めてみたいと思います。このテーマは以前、Kaggleのコンペでも扱われていたことがあったり、調べてみるといくつかのアプローチが存在します。例えば、焼きなまし法を用いたもの、SMTソルバーを駆使したもの、さらに状態にベルヌーイ分布を仮定した確率モデルをMCMCで推定する方法などがありました。\n本稿では、基本的には元の記事と同じアプローチを取り、ライフゲームの時間発展に使用されているルールを微分可能な形式に緩和し、これを勾配降下法による最適化問題として解くことにします。"
  },
  {
    "objectID": "posts/2024-10-20/index.html#ライフゲームの実装",
    "href": "posts/2024-10-20/index.html#ライフゲームの実装",
    "title": "微分可能な比較演算子でライフゲームを逆算する",
    "section": "ライフゲームの実装",
    "text": "ライフゲームの実装\nライフゲームのようなセル・オートマトンはコモナドを使って実装することができます。この話は以前『コモナドを使った抽象化の威力をライフゲームで試してみた』という記事に書きました。本稿でもその実装を使用するので詳しい仕組みの解説は記事に譲るとします。ただ記事の実装は無限に広がった盤面を仮定していたので、今回は有界で端が存在する盤面を扱うために以下の実装では適切な修正を加えています。\nまずは盤面の基礎となるリストのZipperとその関数の実装です。\n\nimport Control.Comonad\nimport Data.List (unfoldr)\n\n-- | List Zipper\ndata Z a = Z [a] a [a]\n           deriving (Show, Functor, Foldable, Traversable)\n\ninstance Comonad Z where\n  extract (Z _ a _) = a\n  duplicate z = Z (iterate1 left z) z (iterate1 right z)\n  extend f z = Z (f &lt;$&gt; iterate1 left z) (f z) (f &lt;$&gt; iterate1 right z)\n\n-- | 注目している要素をひとつ左にずらす\nleft :: Z a -&gt; Maybe (Z a)\nleft (Z [] _ _) = Nothing\nleft (Z (l:ls) c rs) = Just (Z ls l (c:rs))\n\n-- | 注目している要素をひとつ右にずらす\nright :: Z a -&gt; Maybe (Z a)\nright (Z _ _ []) = Nothing\nright (Z ls c (r:rs)) = Just (Z (c:ls) r rs)\n\n-- | 値を複製する\ndup :: a -&gt; (a, a)\ndup x = (x, x)\n\n-- | 関数を返り値がNothingになるまで繰り返し適用したリストを作成する関数\niterate1 :: (a -&gt; Maybe a) -&gt; a -&gt; [a]\niterate1 f = unfoldr (fmap dup . f)\n\n-- | リストから Z a に変換する\ntoZ :: [a] -&gt; Z a\ntoZ [] = error \"toZ can't take an empty list.\"\ntoZ (x:xs) = Z [] x xs\n\n-- | Z a からリストに変換する\nunZ :: Z a -&gt; [a]\nunZ (Z ls c rs) = ls ++ [c] ++ rs\n\n-- | zip の Z a 版\nzipZ :: Z a -&gt; Z b -&gt; Z (a, b)\nzipZ (Z ls1 c1 rs1) (Z ls2 c2 rs2) = Z (zip ls1 ls2) (c1, c2) (zip rs1 rs2)\n\n-- | zipWith の Z a 版\nzipZWith :: (a -&gt; b -&gt; c) -&gt; Z a -&gt; Z b -&gt; Z c\nzipZWith f za zb = uncurry f &lt;$&gt; zipZ za zb\n\n次に盤面の型となる Z2 a とその関数を実装します。\n\n--   ライフゲームの盤面を表す型\nnewtype Z2 a = Z2 (Z (Z a))\n           deriving (Show, Functor, Foldable, Traversable)\n\ninstance Comonad Z2 where\n  extract (Z2 zz) = extract (extract zz)\n  duplicate (Z2 zz) = fmap Z2 . Z2 . roll $ roll zz\n    where\n      roll zz = Z (iterate1 (mapM left) zz) zz (iterate1 (mapM right) zz)\n\n-- | リストから Z2 a に変換する\ntoZ2 :: [[a]] -&gt; Z2 a\ntoZ2 [] = error \"toZ2 can't take an empty list.\"\ntoZ2 (x:xs) = Z2 (Z [] (toZ x) (map toZ xs))\n\n-- | Z2 a からリストに変換する\nunZ2 :: Z2 a -&gt; [[a]]\nunZ2 (Z2 (Z lzs cz rzs)) = map unZ lzs ++ [unZ cz] ++ map unZ rzs\n\n-- | zipWith の Z2 a 版\nzipZ2With :: (a -&gt; b -&gt; c) -&gt; Z2 a -&gt; Z2 b -&gt; Z2 c\nzipZ2With f (Z2 (Z lzs1 cz1 rzs1)) (Z2 (Z lzs2 cz2 rzs2)) =\n  Z2 (Z (zipWith (zipZWith f) lzs1 lzs2)\n        (zipZWith f cz1 cz2)\n        (zipWith (zipZWith f) rzs1 rzs2))\n\nZ a と Z2 a は後に自動微分で使いたいので Traversable のインスタンスまで導出しています。\n最後にライフゲームの状態発展を計算する関数を実装しましょう\n\n--   空リストに対する操作を安全にする関数\nsafe :: ([a] -&gt; a) -&gt; [a] -&gt; Maybe a\nsafe f [] = Nothing\nsafe f xs = Just $ f xs\n\n-- | 近傍の1列で生きているセルをカウントする関数\ncountNeighbour :: Bool  -- Trueなら中心もカウントする\n               -&gt; Z Bool\n               -&gt; Int\ncountNeighbour self (Z ls c rs) = length $ filter id [\n  Just True == safe head ls,\n  self && c,\n  Just True == safe head rs\n  ]\n\n-- | 近傍で生きているセルをカウントする関数\ncountNeighbours :: Z2 Bool -&gt; Int\ncountNeighbours (Z2 (Z lzs cz rzs)) = sum [\n  maybe 0 (countNeighbour True) (safe head lzs),\n  countNeighbour False cz,\n  maybe 0 (countNeighbour True) (safe head rzs)\n  ]\n\n-- | 1セルにおけるライフゲームの状態発展\nlife :: Z2 Bool -&gt; Bool\nlife z = (a && (n == 2 || n == 3)) || (not a && n == 3) where\n  a = extract z\n  n = countNeighbours z\n\nコモナドのメソッド extend と1セルにおける状態発展の関数 life を使って、盤面全体の状態発展の関数は extend life と実装することができます。\n実装したライフゲームを使って試しにブリンカーを動かしてみましょう。\n\nblinker :: Z2 Bool\nblinker = toZ2 [[False, True, False], [False, True, False], [False, True, False]]\n\nextend life blinker\n\nZ2 (Z [] (Z [] False [False,False]) [Z [] True [True,True],Z [] False [False,False]])\n\n\n\nextend life $ extend life blinker\n\nZ2 (Z [] (Z [] False [True,False]) [Z [] False [True,False],Z [] False [True,False]])\n\n\nブリンカーのパタパタする様子が心の目で見えましたでしょうか。\nZ2 a を標準の出力で確認するには限界があるので画像として扱えるようにしておきましょう。\n\nimport Codec.Picture\n\n-- 二重リストを画像に変換する関数\nstateToImage :: Z2 Bool -&gt; Image Pixel8\nstateToImage z2 = generateImage pixelRenderer width height\n  where\n    lst = unZ2 z2\n    width = length (head lst)\n    height = length lst\n    pixelRenderer x y = pixelValue ((lst !! y) !! x)\n    pixelValue x = if x then 0 else 255\n\n\nstateToImage blinker\n\n\n\n\n\n\n\n\n\nstateToImage $ extend life blinker\n\n\n\n\n\n\n\n\n状態を1ピクセルにしたのでかなり小さいですが拡大して見て頂ければうまく動いてることがわかると思います。"
  },
  {
    "objectID": "posts/2024-10-20/index.html#画像の読み込み",
    "href": "posts/2024-10-20/index.html#画像の読み込み",
    "title": "微分可能な比較演算子でライフゲームを逆算する",
    "section": "画像の読み込み",
    "text": "画像の読み込み\nここからは今回ライフゲームで逆算するもととなる画像データを読み込んでいきます。画像データは “image.txt” というファイルに以下のような形式で用意しています。\n\ntake 100 &lt;$&gt; readFile \"image.txt\"\n\n\"w699b11w183b20w177b26w172b31w167b35w163b39w160b45w153b50w148b53w146b55w144b57w142b58w141b64w135b66w2\"\n\n\nこれは200×200の0と1（白と黒）のビット列を一列にし白（w）が連続して何個並ぶかと黒（b）が連続して何個並ぶかという形式で圧縮したテキストファイルです。要するに画像をランレングス圧縮したものです。今回の画像では生のテキストだと40KB, png画像形式で4KB, ランレングス圧縮だと3KBになり相性が良かったので採用しています。まずはこの圧縮された形式をデコードして画像ファイルに戻してあげましょう。\n\nimport Data.Char (isDigit)\n\n-- | ランレングス圧縮された文字列をデコードする関数\ndecodeRLE :: String -&gt; String\ndecodeRLE [] = []\ndecodeRLE (x:xs) =\n  let (n, rest) = span isDigit xs\n   in replicate (read n) x ++ decodeRLE rest\n\n-- | 与えられたリストをN個ずつのチャンクに分ける関数\nchunksOf :: Int -&gt; [a] -&gt; [[a]]\nchunksOf _ [] = []\nchunksOf n xs = take n xs : chunksOf n (drop n xs)\n\n-- | 画像ファイルを読み込む\ntargetState &lt;- (toZ2 . chunksOf 200 . map (=='b') . decodeRLE) &lt;$&gt; readFile \"image.txt\"\n\nこれで targetState に画像がライフゲームの状態として束縛されています。実際に見てみましょう。\n\nstateToImage targetState\n\n\n\n\n\n\n\n\nうまく行っていますね。これはライフゲームの状態でもあるので1ステップ発展させてみましょう。\n\nstateToImage $ extend life targetState\n\n\n\n\n\n\n\n\n黒が多い部分は過密状態なのでセルが死んでしまっているのが分かりますね。\nもう1,2ステップ時間発展させてみましょう。\n\nstateToImage $ extend life $ extend life targetState\n\n\n\n\n\n\n\n\n\nstateToImage $ extend life $ extend life $ extend life targetState\n\n\n\n\n\n\n\n\nうわぁ… ライフゲームっぽくなってきましたね😅"
  },
  {
    "objectID": "posts/2024-10-20/index.html#微分可能なライフゲーム",
    "href": "posts/2024-10-20/index.html#微分可能なライフゲーム",
    "title": "微分可能な比較演算子でライフゲームを逆算する",
    "section": "微分可能なライフゲーム",
    "text": "微分可能なライフゲーム\nさてここからはライフゲームの1つ前の状態を推定することを考えていきたいと思います。この問題を最適化問題として定式化するにあたって誤差関数を考えます。単純に入力となる状態 \\(Y\\) を \\({\\rm life}\\) 関数によって時間発展させたときにターゲットとなる画像 \\(X\\) との差分の平均二乗誤差を誤差関数としましょう。\n\\[\nL(Y) = \\frac{1}{n}\\|X - {\\rm life}(Y)\\|^2\n\\]\nさてこの誤差を最小にするような \\(Y\\) を見つけるためには \\(L\\) を \\(Y\\) で微分する必要がありますが、そのためには \\({\\rm life}\\) が微分可能な関数である必要があります。しかし状態は真偽値であり \\({\\rm life}\\) は論理式で構成されているため微分可能な関数ではありません。\nそこでファジィ論理や確率論理と同様に真偽値を \\([0, 1]\\) の値として連続的に扱えるように拡張しましょう。その場合に論理式やプログラムの制御構文がどのように微分可能な形に拡張できるかについては “The Elements of Differentiable Programming” の5章 Control flows に詳細な記述があります。\n例えば真偽値を \\(\\{0, 1\\}\\) とすると2つの実数を比較して1つ目の数が2つ目の数より大きいかどうかを返す関数 \\({\\rm gt}(x, y)\\) は\n\\[\n\\begin{matrix}\n{\\rm gt}(x, y) &=& \\begin{cases}\n1,\\ {\\rm if}\\ x\\geq y\\\\\n0,\\ {\\rm otherwise}\\\\\n\\end{cases} \\\\\n&=& {\\rm step}(x-y)\n\\end{matrix}\n\\]\nのように書けます。 ここで \\({\\rm step}\\) 関数は以下のように定義されているものです。\n\\[\n{\\rm step}(x) = \\begin{cases}\n1,\\ {\\rm if}\\ x \\geq 0\\\\\n0,\\ {\\rm otherwise} \\\\\n\\end{cases}\n\\]\nこれを \\([0, 1]\\) に値を取るように微分可能な形に緩和すると \\({\\rm step}\\) 関数をシグモイド関数 \\({\\rm sigmoid}\\) にするのがすぐに思いつく方法でしょう。\n\\[\n{\\rm sigmoid}_D(x) = \\frac{1}{1+\\exp\\left(-\\frac{x}{D}\\right)}\n\\]\nこれを使って微分可能な形に緩和した比較関数 \\({\\rm gt}_D(x, y)\\) を\n\\[\n{\\rm gt}_D(x, y) = {\\rm sigmoid}_D(x-y)\n\\]\nと定義します。実はシグモイド関数に置き換えたこの関数は変数がある確率分布に従うと仮定して期待値をとったものと解釈することも可能です。\n同様の方法で”小なり”や”等号”に対応する関数を定義することも可能です。（先に挙げた“The Elements of Differentiable Programming”で \\({\\rm lt}(x, y) = 1 - {\\rm gt}(x, y)\\) と定義されており、これだと後述する否定を使って \\({\\rm lt}(x, y) = {\\rm not}({\\rm gt}(x, y))\\) と書けるため等号部分が異なる気がするのですが、この部分は微分可能な形に緩和すれば確率0で気にならなくなるので本稿でも同様に実装することにします。）\n\\([0, 1]\\) に値を取る真偽値の論理演算子は以下のように定義することができます。\nまず否定 \\({\\rm not}\\) は0を1に、1を0に移すので単純に1からの減算と考えれるでしょう。\n\\[\n{\\rm not}(x) = 1 - x\n\\]\n次に論理積 \\({\\rm and}(x, y)\\) は \\(x, y\\) いずれかの値が0なら0になり両方が1なら1になります。単純な積はこの性質を満たしていることがわかるでしょう。\n\\[\n{\\rm and}(x, y) = xy\n\\]\n次に論理和 \\({\\rm or}(x, y)\\) は \\(x, y\\) いずれかの値が1なら1になり両方が0なら0になります。このような性質を満たす計算を見つけるのは簡単ではありませんが、既に否定と論理積があるのでド・モルガンの法則を使って\n\\[\n\\begin{matrix}\n{\\rm or}(x, y) &=& {\\rm not}({\\rm and}({\\rm not}(x), {\\rm not}(y))) \\\\\n&=& 1 - (1-x)(1-y) \\\\\n&=& x + y - xy \\\\\n\\end{matrix}\n\\]\nのように定義できることが分かります。\nこのように論理和・論理積を \\([0, 1]\\) に拡張したものは代数和・代数積と呼ばれていて実は上記の定義以外にも無数に存在することが知られています。気になる人は以下を参照してみてください。\n\nファジィ理論とその応用 | Mathlog\nT-norm - Wikipedia\n\nif などの制御構文も微分可能な形に実装することができますが、今回のライフゲームの実装では必要ありません。上記を参考に微分可能な比較演算子と論理演算子を実装してみましょう。\n\n--   x &gt; y\ngtD :: Floating a =&gt; a -&gt; a -&gt; a\ngtD x y = 1 / (1 + exp (-4 * (x - y)))\n\n-- | x &lt; y\nltD :: Floating a =&gt; a -&gt; a -&gt; a\nltD x y = 1 - gtD x y\n\n-- | x == y\neqD :: Floating a =&gt; a -&gt; a -&gt; a\neqD x y = exp $ -(4 * (x - y))^2/2\n\n-- | !x\nnotD :: Num a =&gt; a -&gt; a\nnotD x = 1 - x\n\n-- | x && y\nandD :: Num a =&gt; a -&gt; a -&gt; a\nandD x y = x * y\n\n-- | x || y\norD :: Num a =&gt; a -&gt; a -&gt; a\norD x y = x + y - x * y\n\n-- | x ≧ y\ngeqD :: Floating a =&gt; a -&gt; a -&gt; a\ngeqD x y = eqD x y `orD` gtD x y\n\n-- | x ≦ y\nleqD :: Floating a =&gt; a -&gt; a -&gt; a\nleqD x y = eqD x y `orD` ltD x y\n\ngtD と ltD は引数が一致する場合に値が \\(\\frac{1}{2}\\) となるため等号のない \\(&gt;, &lt;\\) を表していると解釈し、等号も含めた演算子 \\(\\geq, \\leq\\) を別途 geqD, leqD として実装しています。\nそれではこれらの演算子を使ってライフゲームの微分可能な状態発展を実装してみましょう。\n\nimport Data.Maybe (fromMaybe)\n\n-- | 近傍の1列で生きているセルを合計する関数\nsumNeighbour :: Num a\n             =&gt; Bool  -- Trueなら中心もカウントする\n             -&gt; Z a\n             -&gt; a\nsumNeighbour self (Z ls c rs) = sum [\n  fromMaybe 0 (safe head ls),\n  if self then c else 0,\n  fromMaybe 0 (safe head rs)\n  ]\n\n-- | 近傍で生きているセルを合計する関数\nsumNeighbours :: Num a\n              =&gt; Z2 a\n              -&gt; a\nsumNeighbours (Z2 (Z lzs cz rzs)) = sum [\n  maybe 0 (sumNeighbour True) (safe head lzs),\n  sumNeighbour False cz,\n  maybe 0 (sumNeighbour True) (safe head rzs)\n  ]\n\n-- | 1セルにおけるライフゲームの微分可能な状態発展\nlifeD :: Floating a =&gt; Z2 a -&gt; a\nlifeD z = (a `andD` (geqD n 2 `andD` leqD n 3)) `orD` (notD a `andD` eqD n 3)\n  where\n    a = extract z\n    n = sumNeighbours z\n\nlifeD の実装をよく見ると Bool に対する life の実装とよく対応していることが分かります。\nlife :: Z2 Bool -&gt; Bool\nlife z = (a && (n == 2 || n == 3)) || (not a && n == 3) where\n  a = extract z\n  n = countNeighbours z\n実際に lifeD を使ってライフゲームを状態発展させてみましょう。\n\nstateToImage $ fmap (&gt; 0.5) $ extend lifeD $ (\\b -&gt; if b then 1.0 else 0.0) &lt;$&gt; targetState\n\n\n\n\n\n\n\n\n先程見た結果と一致していそうですね。"
  },
  {
    "objectID": "posts/2024-10-20/index.html#つ前の状態を推定する",
    "href": "posts/2024-10-20/index.html#つ前の状態を推定する",
    "title": "微分可能な比較演算子でライフゲームを逆算する",
    "section": "1つ前の状態を推定する",
    "text": "1つ前の状態を推定する\nそれでは勾配降下法を使って目標となる画像に発展する1つ前の状態を求めてみましょう。入力となるセルの値が \\([0,1]\\) だと途中で範囲外に出てしまう可能性があるため、値は実数を取れるようにしてシグモイド関数で \\([0, 1]\\) に含まれるように変換することにします。自動微分には ad ライブラリを使用しています。\n\nimport Data.Function (fix)\n\nimport Graphics.Rendering.Chart.Easy\nimport Numeric.AD\nimport System.Random (randomIO)\n\n\n(resultState, losses) &lt;- do\n  -- 初期状態をランダムに作成\n  initialState &lt;- toZ2 . chunksOf 200 . map (\\b -&gt; if b then 1 else -1) &lt;$&gt; sequence (replicate (200 * 200) randomIO)\n  let -- ターゲットとなる画像を Z2 Float に変換\n      target = (\\b -&gt; if b then 1 else 0) &lt;$&gt; targetState\n      -- 定義域を [0, 1] から実数全体にするためシグモイド関数で変換する\n      sigmoid x = 1 / (1 + exp (-x))\n      -- 誤差関数\n      loss state = sum . fmap (^2) $ zipZ2With (-) target (extend lifeD (fmap sigmoid state))\n      -- エポック数\n      epoch = 12000\n  -- 初期値の誤差を表示する\n  putStrLn $ concat [\"initial, loss = \", show (loss target)]\n  -- 勾配降下法で最適化を行う\n  flip fix (initialState, epoch, []) $ \\loop (state, n, losses) -&gt; do\n    if n == 0\n      -- n が 0 になったら結果を整形して終了\n      then pure (fmap sigmoid state, reverse losses)\n      else do\n        let -- 勾配降下法\n            state' = zipZ2With (-) state (fmap (0.1*) (grad loss state))\n            -- 誤差の評価\n            !l = loss state'\n        -- 定期的に進捗をログに出力する\n        if mod n 1000 == 0\n          then putStrLn $ concat [\"n = \", show (epoch - n), \", loss = \", show l]\n          else pure ()\n        -- 状態を更新してループする\n        loop (state', n-1, l:losses)\n\ntoRenderable $ plot (line \"\" [zip [0..] losses])\n\ninitial, loss = 14174.446314774947\nn = 0, loss = 12437.558591909137\nn = 1000, loss = 669.9011793628988\nn = 2000, loss = 581.6638456947436\nn = 3000, loss = 547.3427997406984\nn = 4000, loss = 524.5258231500682\nn = 5000, loss = 511.03811378437507\nn = 6000, loss = 500.1939355743127\nn = 7000, loss = 489.87961196569944\nn = 8000, loss = 484.3542493674258\nn = 9000, loss = 479.40304896751013\nn = 10000, loss = 476.66751555896707\nn = 11000, loss = 474.38607336184685\n\n\n\n\n\n\n\n\n\nグラフから誤差を小さくできていることが分かりますね👏 ループの部分はflip fix を使って雑に書いていますが適切なfold系の関数を使って実装することも可能でしょう。\n得られた結果がどうなっているか確認しましょう。\n\nstateToImage $ fmap (&gt; 0.5) resultState\n\n\n\n\n\n\n\n\n既にかなり面影があります😅 これをライフゲームとして1ステップ状態発展させてみましょう。\n\nstateToImage $ extend life $ fmap (&gt; 0.5) resultState\n\n\n\n\n\n\n\n\n見事目標としていた画像に近いパターンが得られています。\nライフゲームのルール上黒いベタ塗りなどは表現しにくいのですが、元記事でも指摘されているように1つ前の状態としてチューリング・パターンのような模様が現れているのは不思議ですよね👀"
  },
  {
    "objectID": "posts/2020-07-09/index.html",
    "href": "posts/2020-07-09/index.html",
    "title": "2点テイラー展開の定義と数値実験",
    "section": "",
    "text": "テイラー展開は滑らかな関数の一点における値や微分の値を使ったべき級数によって元の関数を表す方法でした。\n\\[\nf(x) = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2!}\\left(x-a\\right)^2 + \\frac{f'''(a)}{3!}\\left(x-a\\right)^3 + \\cdots\n\\]\nこれを2点以上に拡張したテイラー展開が存在していて、特に2点でテイラー展開を行うものは2点テイラー展開と呼ばれているそうです。\nなんで2点でテイラー展開したくなるのかというと、普通のテイラー展開だと1点における2n階までの微分値を使わないと達成できない近似精度を2点テイラー展開だと2点におけるn階までの微分値で達成できたりするそうなのですが（スゴイ！）[^1]、個人的には2点でテイラー展開することで区分的に定義された関数も近似できるのが面白いなと思いました。\nテイラー展開は1点の周りにおける情報しか使わないので通常近似できる範囲はその1点の近くまでです。特に関数が折れ線だったり、ReLUのように各領域によって違う関数の組み合わせで表されている場合には領域を区分する点をまたいで近似できる範囲を拡張することができません。そこで2点テイラー展開を使えば区分する点をまたいだ2点の周りで展開することによりそれぞれの点の周りの情報を使ってテイラー展開よりも近似できる範囲を拡張することができるのです。以下の定理はこのことをより正確に表しています[^2]。\nTheorem. \\(f\\)を\\({\\mathbb R}\\)上の以下のように表される関数とする。\n\\[\nf(x) = \\begin{cases} p(x)\\ \\ x \\in [0, \\infty) \\\\ q(x)\\ \\ x \\in (-\\infty, 0) \\end{cases}\n\\]\nここで\\(p, q\\)は高々\\(m\\)次の多項式とする。この時、もし\\(p(0)=q(0)\\)であるならば\\(f(x)\\)は-1, 1において2点テイラー展開可能であり、\\(p_{f,\\{-1, 1\\}(n, n)}(x)\\)をエルミート補間多項式だとすると以下が成り立つ。\n\\[\n\\underset{n \\rightarrow \\infty}{\\lim}p_{f,\\{-1, 1\\}(n, n)}(x)=f(x), \\forall x \\in \\left(-\\sqrt 2, \\sqrt 2\\right)\n\\]\nところでまだ2点テイラー展開の定義をしていませんでした。2点テイラー展開は多項式補間の考え方を経由して定義されます。\n（以下の説明は[^2]の導入部分を大いに参考にしています）\n十分になめらかな実数値関数\\(f(x)\\)に対して\\(n\\)個の点\\(X = \\{x_0,\\dots,x_n\\}\\)とそれぞれの点に対応する自然数\\(k_i(0\\leq i\\leq n)\\)が与えられた時、高々\\(m(=k_0+\\cdots+k_n-1)\\)次の多項式\\(p_{f,X(k_0,\\dots,k_n)}(x)\\)が存在して\n\\[\np^{(j)}_{f,X(k_0,\\dots,k_n)}(x_i) = f^{(j)}(x_i), 0\\leq j \\leq k_i-1, 0 \\leq i \\leq n\n\\]\nを満たす時、\\(p_{f,X(k_0,\\dots,k_n)}(x)\\)を\\(f(x)\\)のエルミート補間多項式と呼びます。\nもし\\(f(x)\\)が一点\\(x_0\\)の周りで無限回微分可能であり、ある正の実数\\(\\rho\\)が存在して\n\\[\n\\underset{n \\rightarrow \\infty}{\\lim} p_{f,X(n)}(x) = f(x), \\forall x \\in (x_0-\\rho, x_0+\\rho)\n\\]\nとなるならば\\(f(x)\\)は同じ範囲でテイラー展開可能であることが分かります。\nこの事実を発展させて\\(n\\)点テイラー展開は以下のように定義されます。\n\\(f\\)をある区間\\(I\\)で定義された実数値関数とし、\\(I\\)に含まれる\\(n\\)個の点\\(X=\\{x_0,\\dots x_{n-1}\\}\\)で\\(f\\)が無限回微分可能であったとする。もし\n\\[\n\\underset{m \\rightarrow \\infty}{\\lim} p_{f,X(m,\\dots,m)}(x) = f(x), \\forall x \\in I\n\\]\nが成り立つならば\\(f\\)は\\(I\\)において\\(n\\)点テイラー展開可能であるという。\n\\(n\\)点テイラー展開の具体的な形は、エルミート補間多項式の一般公式が知られているので[^3]そちらから計算可能でしょう。特に2点テイラー展開の場合の級数の計算式は以下のようにできるとTwitterで教えてもらいました[^4]。（そもそも2点テイラー展開を知ったきっかけも、このnotebookを書こうと思ったのも島田さんのTweetに触発されてでした。感謝🙏）"
  },
  {
    "objectID": "posts/2020-07-09/index.html#数値実験",
    "href": "posts/2020-07-09/index.html#数値実験",
    "title": "2点テイラー展開の定義と数値実験",
    "section": "数値実験",
    "text": "数値実験\n比較のためにまずは通常のテイラー展開を実装してみます\n\n{-# LANGUAGE RankNTypes #-}\n\nimport Data.Number.Symbolic\n\nimport Numeric.AD\nimport Numeric.AD.Mode.Tower\n\n\n-- 階乗\nfact :: Int -&gt; Int\nfact n = product [1..n]\n\n\n-- テイラー展開\ntaylorSeries :: Fractional a\n             =&gt; Int                                          -- この次数以下の級数まで展開する\n             -&gt; (forall s. AD s (Tower a) -&gt; AD s (Tower a)) -- テイラー展開する関数\n             -&gt; a                                            -- 展開する点\n             -&gt; (a -&gt; a)                                     -- 展開後の級数\ntaylorSeries n f a x = sum $ take n $ coefficients |*| polynomials\n  where\n  coefficients = diffs f a |/| factorials      -- f(a)/0!, f'(a)/1!, f''(a)/2!, f'''(a)/3!, ...\n  factorials = map (fromIntegral . fact) [0..] -- 0!, 1!, 2!, 3!, ...\n  polynomials = ((x - a)^) &lt;$&gt; [0..]           -- 1, x-a, (x-a)^2, (x-a)^3, ...\n  (|/|) = zipWith (/)\n  (|*|) = zipWith (*)\n\n\ntaylorSeries 4 exp 0 (var \"x\")\n\n1.0+x+0.5*x*x+0.16666666666666666*x*x*x\n\n\n4次までの指数関数のテイラー展開をちゃんと計算できていますね\n\\[\n1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!}\n\\]\n次は2点テイラー展開を実装してみましょう\n\n-- 2点テイラー展開\ntwoPointTaylorSeries :: Fractional a\n                     =&gt; Int                                          -- この次数以下の級数まで展開する\n                     -&gt; (forall s. AD s (Tower a) -&gt; AD s (Tower a)) -- テイラー展開する関数\n                     -&gt; a                                            -- 展開する点1\n                     -&gt; a                                            -- 展開する点2\n                     -&gt; (a -&gt; a)                                     -- 展開後の級数\ntwoPointTaylorSeries n f a b x = seriesA + seriesB\n  where\n  seriesA = (x - a) ^ n * sum (take n $ coefB |*| polyB)\n  seriesB = (x - b) ^ n * sum (take n $ coefA |*| polyA)\n  fa x = f x / (x - auto b)^n        -- A(x)\n  fb x = f x / (x - auto a)^n        -- B(x)\n  coefA = diffs fa a |/| factorials  -- A(a)/0!, A'(a)/1!, A''(a)/2!, A'''(a)/3!, ...\n  coefB = diffs fb b |/| factorials  -- B(b)/0!, B'(b)/1!, B''(b)/2!, B'''(b)/3!, ...\n  polyA = ((x - a)^) &lt;$&gt; [0..]       -- 1, x-a, (x-a)^2, (x-a)^3, ...\n  polyB = ((x - b)^) &lt;$&gt; [0..]       -- 1, x-b, (x-b)^2, (x-b)^3, ...\n  factorials = map (fromIntegral . fact) [0..] -- 0!, 1!, 2!, 3!, ...\n  (|/|) = zipWith (/)\n  (|*|) = zipWith (*)\n\n\ntwoPointTaylorSeries 2 id (-1) 1 (var \"x\") -- id ≡ f(x) = x\n\n0.25*(1.0+x)*(1.0+x)+(-0.25)*(-1.0+x)*(-1.0+x)\n\n\n式が複雑になるので\\(f(x)=x\\)という単純な関数を展開して確かめてみました。式を整理するとちゃんと正しい答えになってるのが分かります。\nそれでは実際に関数を近似してみましょう\nまずは\n\\[\n\\frac{1}{1+x^2}\n\\]\nという関数を展開してみましょう\n\nimport Graphics.Rendering.Chart.Easy\n\ncauchy :: Floating a =&gt; a -&gt; a\ncauchy x = 1 / (1 + x^2)\n\ndomain :: [Double]\ndomain = map (\\n -&gt; fromIntegral n / 100) [-100..100]\n\ntoRenderable $ do\n    plot (line \"cauchy\"    [flip map domain $ \\x -&gt; (x, cauchy x)])\n    plot (line \"one point\" [flip map domain $ \\x -&gt; (x, taylorSeries 5 cauchy 0 x)])\n    plot (line \"two point\" [flip map domain $ \\x -&gt; (x, twoPointTaylorSeries 5 cauchy (-1) 1 x)])\n\n\n\n\n\n\n\n\n青線が元の関数、緑線が\\(0\\)周りでの5次までのテイラー展開、赤線が\\(-1, 1\\)周りでの5次までの2点テイラー展開です。同じ次数までの展開ですが2点テイラー展開のほうがより高い精度で近似できているのが分かります\n次に区分的に定義された関数であるReLUを展開してみましょう\n\nrelu :: (Ord a, Floating a) =&gt; a -&gt; a\nrelu = max 0\n\ntoRenderable $ do\n    plot (line \"ReLU\"      [flip map domain $ \\x -&gt; (x, relu x)])\n    plot (line \"one point\" [flip map domain $ \\x -&gt; (x, taylorSeries 5 relu 1 x)])\n    plot (line \"two point\" [flip map domain $ \\x -&gt; (x, twoPointTaylorSeries 5 relu (-1) 1 x)])\n\n\n\n\n\n\n\n\nテイラー展開は\\(1\\)の周りで展開していますがやはり0以下で関数が変わっていることには対応できていません。一方で2点テイラー展開は\\(1\\)の周りに加えて\\(-1\\)の周りの情報もつかえているのでReLUの形をより正確に近似できているのが分かります。"
  },
  {
    "objectID": "posts/2020-07-09/index.html#参考文献",
    "href": "posts/2020-07-09/index.html#参考文献",
    "title": "2点テイラー展開の定義と数値実験",
    "section": "参考文献",
    "text": "参考文献\n\n[1] Estes, R. H., and E. R. Lancaster. “Two-point Taylor series expansions.” (1966).\n[2] Kitahara, Kazuaki, Taizo Chiyonobu, and Hirokazu Tsukamoto. “A note on two point Taylor expansion.” International Journal of Pure and Applied Mathematics 75.3 (2012): 327-338.\n[3] 鈴木 実, “エルミート補間の一般公式（Generalized Hermite interpolation）” http://totoha.web.fc2.com/Hermite_interpolation.pdf\n[4] https://twitter.com/KS_Mathematics/status/1279807348391854080"
  },
  {
    "objectID": "posts/2024-03-23/index.html",
    "href": "posts/2024-03-23/index.html",
    "title": "Haskellで実装するk-means法とk-means++法",
    "section": "",
    "text": "k-means問題はクラスタリングに関する問題で、データの集合を\\(X\\)、クラスタ数を\\(k\\)とした時に、\\(X\\)の分割\\(S = \\{S_1, S_2, \\dots, S_k\\}\\) の中で以下のコスト関数\n\\[\n\\underset{S}{\\arg\\min} \\sum_{i=1}^k\\sum_{x\\in S_i}\\|x-\\mu_i\\|^2\n\\]\nを最小にするものを見つけることが目的です。\nここで \\(\\mu_i\\) はクラスタの中心で\n\\[\n\\mu_i = \\frac{1}{|S_i|}\\sum_{x\\in S_i}x\n\\]\nと平均値で計算されることが多いです。\n\nk-means法\nこの問題はNP困難であることが知られていますが、k-means法（Lloydアルゴリズム）と呼ばれる局所解を高速に与える有名なアルゴリズムがあります。それは以下のようなものです。\n\nクラスタの中心としてデータ点からランダムにk個を選ぶ\n各データ点を中心が最も近いクラスタに分類する\n各クラスタに属するデータから改めて中心を計算する\n収束するまで2,3を繰り返す\n\nアルゴリズムのイメージは実際に視覚的に見てみるのが分かりやすいでしょう。以下のサイトがk-means法を可視化してくれていてインタラクティブに試すことができるのでオススメです。\n\nK-means 法を D3.js でビジュアライズしてみた\n\nHaskellにもk-means法を実装したライブラリはあります。\n\nkmeans\nkmeans-vector\nclustering\n\nですが今回は自分で実装します。\n\n{-# LANGUAGE BlockArguments, DataKinds #-} \n\nimport GHC.TypeLits\n\nimport qualified Data.Vector.Sized as V\n\n\n-- | ボロノイ分割\nvoronoiDecompose :: (KnownNat (n+1), Ord b)\n                 =&gt; (a -&gt; a -&gt; b)       -- 距離関数\n                 -&gt; [a]                 -- データ点\n                 -&gt; V.Vector (n+1) a    -- 中心点\n                 -&gt; V.Vector (n+1) [a]  -- ボロノイ分割\nvoronoiDecompose distance ds cs =\n  V.accum (flip (:)) (V.replicate []) $\n    map (\\d -&gt; (V.minIndex $ V.map (distance d) cs, d)) ds\n\n\n-- | k-means法\nkMeans :: (KnownNat (n+1), Eq a, Ord b)\n       =&gt; (a -&gt; a -&gt; b)     -- 距離関数\n       -&gt; ([a] -&gt; a)        -- 集約関数\n       -&gt; [a]               -- データ点\n       -&gt; V.Vector (n+1) a  -- 中心点\n       -&gt; V.Vector (n+1) a  -- 中心点\nkMeans distance aggregate ds cs =\n  let cs' = V.map aggregate $ voronoiDecompose distance ds cs\n   in if cs == cs' then cs' else kMeans distance aggregate ds cs'\n\nvoronoiDecompose は与えられた中心点に従ってデータ点をボロノイ領域で分類する関数です。データ点はリストとして扱っていますが、中心点はランダムアクセスしたいので Vector を使って \\(O(1)\\) アクセスできるようにしています。データ点の型は型変数で抽象化しており、必要になる距離関数は後から与えられるようになっています。\nkMeans はk-means法を計算する関数です。データ点をボロノイ分割した結果を集約して計算した新しい中心点がもとの中心点と一致するまで計算を繰り返します。\n\n\nk-means++法\nkMeans は中心点を更新していく関数として実装していますがそもそもの中心点はどのように用意すれば良いでしょうか。もちろんランダムなデータ点を取ってきても良いのですが、k-means++法と呼ばれる効率の良い中心点の与え方が知られています。k-means++法は以下のようなアルゴリズムです。\n\nデータ点からランダムに1つ目の中心点を選ぶ\nそれぞれのデータ点\\(x\\)に対して、最も近い中心点からの距離\\(D(x)\\)を計算する\nデータ点\\(x\\)につき重み\\(\\frac{D^2(x)}{\\sum_{x\\in X}D^2(x)}\\)を考慮して新しい中心点をランダムに選ぶ\n選ばれた中心点の数が予め与えられたクラスタ数\\(k\\)に到達するまで2,3を繰り返す\n\n感覚的には今ある中心点より遠くにあるデータ点が選ばれやすくなるように新しい中心点を選ぶような形になっています。それなら単純に\\(D(x)\\)に比例した重みでサンプリングしても良さそうなものですが、このアルゴリズムによって選ばれた中心点により評価したk-means問題のコスト関数の値を\\(\\phi\\)とすると、コスト関数の最小値\\(\\phi_{\\rm OPT}\\)に対して\n\\[\n{\\rm E}[\\phi] \\leq 8(\\log k+2)\\phi_{\\rm OPT}\n\\]\nを満たすことが証明できます。この証明にはコーシー・シュワルツの不等式が使われていて二乗の形であることが本質的な役割を果たしているのです（もう少し荒い評価にはなりますが単純に\\(l^p\\)距離を用いた場合の不等式も論文には載っています）。このようにk-means++法は初期の中心点を決めた時点で期待値における理論的な精度評価が得られていますが、更にその後k-means法を用いてコスト関数を単調減少させることにより良いクラスタリングの結果が得られるようになっているのです。\nそれではk-means++法を実装してみましょう。\n\nimport Data.Proxy (Proxy(..))\n\nimport qualified Data.Vector.Generic as VG\nimport qualified Data.Vector.Generic.Sized.Internal as VGSI\nimport Data.Random (randomElement, RVar)\nimport Data.Random.Distribution.Categorical (weightedCategorical)\n\n\n-- ref. https://github.com/expipiplus1/vector-sized/issues/123\nunfoldrM :: forall m n a b. (Monad m, KnownNat n)\n         =&gt; (b -&gt; m (a, b)) -&gt; b -&gt; m (V.Vector n a)\nunfoldrM f z = VGSI.Vector &lt;$&gt; VG.unfoldrExactNM i f z\n  where i = fromIntegral (natVal (Proxy :: Proxy n))\n\n\n-- | k-means++法\nkMeansPlusPlus :: KnownNat n\n               =&gt; (a -&gt; a -&gt; Double)  -- 距離関数\n               -&gt; [a]                 -- データ点\n               -&gt; RVar (V.Vector n a) -- 中心点\nkMeansPlusPlus distance ds = unfoldrM f []\n  where\n  f [] = do\n    c &lt;- randomElement ds\n    pure (c, [c])\n  f cs = do\n    let ws = map (\\d -&gt; minimum $ map (\\c -&gt; distance c d ^2) cs) ds\n    c &lt;- weightedCategorical (zip ws ds)\n    pure (c, c:cs)\n\nk-means++法を実装するためにunfoldrMという便利関数を定義しています。実はvectorライブラリにはこのような関数が定義されているのですがvector-sizedには無いので自前で実装しています（実装して欲しいというissueはあります）。\nunfoldrMを使えばk-means++法は素直に場合分けして実装するだけです。k-means++法はランダムな選択を伴うので何らかのモナドに包む必要があります。IOにしてしまっても良いのですが確率分布もまたそれ自体がモナドになるので、できるだけ抽象的な型に留める形で実装しています。確率分布（確率変数）の型として、ここでは random-fuのRVarを使っています。\n\n\n実験\nそれでは実装したk-means法、k-means++法を使って実際にクラスタリングを行ってみましょう。まずはクラスタリングの対象となる平面上の点を実装していきます。\n\nimport Data.List (foldl')\nimport Data.Maybe (fromJust)\n\n\n-- | 平面上の点\ntype Point = V.Vector 2 Double\n\n\n-- | x, y 座標から点を構築する\nmkPoint :: Double -&gt; Double -&gt; Point\nmkPoint a b = fromJust $ V.fromList [a, b]\n\n\n-- | 距離関数\ndistance :: Point -&gt; Point -&gt; Double\ndistance v1 v2 = sqrt . V.sum . V.map (^2) $ V.zipWith (-) v1 v2\n\n\n-- | 平均値関数\naverage :: [Point] -&gt; Point\naverage ps =\n  let n = fromIntegral $ length ps\n   in V.map (/n) $ foldl' (V.zipWith (+)) (V.replicate 0) ps\n\n最後にこれらの点をランダムにサンプリングしてクラスタリングしてみましょう。クラスタの数は型に現れるので型注釈で与えます。\n\nimport Control.Monad (replicateM)\nimport Data.Traversable (forM)\n\nimport Data.Random (normal, sampleFrom)\nimport Graphics.Rendering.Chart.Easy\nimport System.Random.Stateful (newIOGenM, mkStdGen)\n\n\nsamples :: RVar [Point]\nsamples = concat &lt;$&gt; forM clusters \\(m, s) -&gt;\n  replicateM nEachSamples $ mkPoint &lt;$&gt; normal m s &lt;*&gt; normal m s\n  where\n  nEachSamples = 100  \n  clusters = [(-2, 1), (4, 2)]\n\n\ndo\n  gen &lt;- newIOGenM (mkStdGen 42)\n  ds &lt;- sampleFrom gen samples\n  cs &lt;- sampleFrom gen $\n    kMeansPlusPlus distance ds :: IO (V.Vector 2 Point)  -- k-means++法\n  let cs' = kMeans distance average ds cs  -- k-means法\n      voronoi = voronoiDecompose distance ds cs'\n      toTuple v = (V.index v 0, V.index v 1)\n  pure $ toRenderable $ do\n    plot (points \"Group 1\" . map toTuple $ V.index voronoi 0)\n    plot (points \"Group 2\" . map toTuple $ V.index voronoi 1)"
  },
  {
    "objectID": "posts/2024-05-12/index.html",
    "href": "posts/2024-05-12/index.html",
    "title": "HaskellでQR分解を実装する",
    "section": "",
    "text": "QR分解は与えられた\\(m\\times n\\)行列\\(A\\)を\\(m\\times m\\)のユニタリ行列（実数の場合、直交行列）\\(Q\\)と\\(m\\times n\\)の上三角行列\\(R\\)の積、すなわち\\(A=QR\\)と分解する手法です。 数値的に安定な計算アルゴリズムが知られており、固有値の計算（QR法）やカルマンフィルターの安定的な計算にも応用されています。またこういった分解はより抽象的な対象で考えられることも多く、QR分解は半単純リー群の岩澤分解に一般化されることが知られています。\nQR分解を実現するアルゴリズムはWikipediaにも詳しく載っており\n\nグラム・シュミットの正規直交化法\nハウスホルダー変換\nギブンス回転\n\nを利用した手法などがあります。\nHaskellでも例えば hmatrix が qr というQR分解を行う関数を提供していたり、hmatrixを使ったギブンス回転やハウスホルダー変換によるQR分解の実装を解説した記事もあります（お気楽 Haskell プログラミング入門 線形代数編）。しかし本稿ではあえて vector-sized を使って自分で実装してみようと思い、数値的にも安定しているハウスホルダー変換を利用した実行列のQR分解の実装したいと思います。\n\n即席線形代数\nまずは Haskellで実装する即席線形代数 を参考に実装に必要なベクトルと行列の型と関数の定義を行います。\n\nimport GHC.TypeLits\nimport Text.Printf\n\nimport Data.Vector.Sized (Vector)\nimport qualified Data.Vector.Sized as V\n\ntype Matrix m n a = Vector m (Vector n a)\n\n-- | ベクトルのスカラー倍\n(*^) :: Num a =&gt; a -&gt; Vector n a -&gt; Vector n a\n(*^) a = V.map (*a)\n\n-- | ベクトルをスカラー値で割る\n(^/) :: Fractional a =&gt; Vector n a -&gt; a -&gt; Vector n a\n(^/) v a = recip a *^ v\n\n-- | 内積\ndot :: Num a =&gt; Vector n a -&gt; Vector n a -&gt; a\ndot = (V.sum .) . V.zipWith (*)\n\n-- | 外積\nouter :: Num a =&gt; Vector m a -&gt; Vector n a -&gt; Matrix m n a\nouter xs ys = V.map (\\x -&gt; V.map (*x) ys) xs\n\n-- | ユークリッドノルム\nnorm2V :: Floating a =&gt; Vector n a -&gt; a\nnorm2V = sqrt . V.sum . V.map (^2)\n\n-- | リストから行列を作成する\nfromList :: (KnownNat m, KnownNat n) =&gt; [[a]] -&gt; Maybe (Matrix m n a)\nfromList = (=&lt;&lt;) V.fromList . mapM V.fromList\n\n-- | 行列を整形して表示する\ndisplayM :: PrintfArg a\n         =&gt; Int  -- 数値の表示幅\n         -&gt; Int  -- 有効数字\n         -&gt; Matrix n m a\n         -&gt; IO ()\ndisplayM w p = putStrLn . drop 1 . V.foldl (\\x v -&gt; x ++ '\\n' : V.foldl (++) \"\" (V.map (printf \"%*.*f\" w p) v)) \"\"\n\n-- | 単位行列\nidentity :: (KnownNat n, Num a) =&gt; Matrix n n a\nidentity = V.generate (\\x -&gt; V.generate (\\y -&gt; if x == y then 1 else 0))\n\n-- | 行列のスカラー倍\n(*!!) :: Num a =&gt; a -&gt; Matrix m n a -&gt; Matrix m n a\n(*!!) a = V.map (V.map (*a))\n\n-- | 行列の転置\ntranspose :: KnownNat n =&gt; Matrix m n a -&gt; Matrix n m a\ntranspose = sequenceA\n\n-- | 行列積\n(!*!) :: (KnownNat r, Num a) =&gt; Matrix m n a -&gt; Matrix n r a -&gt; Matrix m r a\na !*! b = fmap (flip fmap (transpose b) . dot) a\n\n\n\nハウスホルダー変換\nハウスホルダー変換は与えられたベクトル\\(x\\)を単位法線ベクトル\\(v\\)で表された原典を通る超平面で鏡映変換する変換です。変換後のベクトルは \\(x - 2 v \\langle v, x \\rangle\\) と表すことができ、これは行列 \\(I - 2vv^{\\rm T}\\)を\\(x\\)に左から掛けて変換していると考えることもできます。このハウスホルダー変換を使えば、与えられた行列の列ベクトルを左から順番に第n成分までの部分空間に射影していくことでQR分解を得ることができます。\nアルゴリズムの詳しい解説は他の記事に譲るとして（例えばWikipedia）、さっそく実装を見ていきたいと思います。以下 householder として実装するのは添字\\(i\\)とベクトル\\(x\\)が与えられた時に、\\(x\\)の第\\(i\\)成分以降を第\\(i\\)成分までの部分空間に射影する（すなわち残りの成分を0にする）ハウスホルダー変換を表す行列を計算する関数です。\n\nimport Data.Maybe (fromJust)\n\nimport Data.Finite (Finite)\nimport qualified Data.Vector as V'\n\n-- | ハウスホルダー変換\nhouseholder :: (KnownNat n, Ord a, Floating a) =&gt; Finite n -&gt; Vector n a -&gt; Matrix n n a\nhouseholder i' x =\n  let i = fromIntegral i'\n      y = V'.drop i $ V.fromSized x\n      u = y V'.// [(0, V'.head y - y `V.withSized` norm2V)]\n      padding = (V'.++) (V'.replicate i 0)\n      u_norm = u `V.withSized` norm2V\n      v = fromJust . V.toSized . padding $ V'.map (/u_norm) u\n   in if abs u_norm &lt; 1e-12 then identity else identity - 2 *!! outer v v\n\nベクトルと行列の型にはサイズに関する情報を持たせていますが householder では最初からその情報を捨てて素の Data.Vector で変換を行っています。理由としてはハウスホルダー変換を計算するベクトルの長さ（すなわち型）は第一引数である i' の値に依存しており、今のHaskellの依存型だと今回の様な状況では簡潔に実装できる方法がないため型からサイズの情報を削ることにしました。\n実装中に単位法線ベクトル\\(v\\)を計算するために法線ベクトル\\(u\\)をそのノルムで割る処理がありますが、\\(u\\)のノルムが非常に小さい場合この処理は不安定になります。しかし\\(u\\)のノルムが非常に小さいということは\\(x\\)と変換後のベクトルがほぼ等しいという状況を表しており、このような場合には結果となる変換行列をただの単位行列にするようにしています。\n\n\nQR分解\nQR分解は与えられた行列の列ベクトルを左から順番にハウスホルダー変換して上三角行列を作ることにより得ることができます。\n\n{-# LANGUAGE ScopedTypeVariables #-}\n\nimport Data.Proxy\n\nimport Data.Finite (finite)\n\nqr :: forall m n a. (KnownNat m, KnownNat n, Ord a, Floating a) =&gt; Matrix m n a -&gt; (Matrix m m a, Matrix m n a)\nqr a =\n  transpose &lt;$&gt;\n    foldl (\\(q, r) i -&gt;\n      let p = householder (finite i) (V.index r (finite i))\n       in (q !*! p, r !*! p)\n    ) (identity, transpose a) [0..k-1]\n  where k = fromInteger $ min (natVal (Proxy @n)) (natVal (Proxy @m))\n\n実装上の都合で行列は行ベクトルのベクトルとなっているので、列ベクトルを扱うために最初に転置を行い\\(A^{\\rm T}\\)、得られた\\(R^{\\rm T}\\)を最後にもう一度転置することにより計算しています。\\(Q\\)については本来転置したものが計算結果になるのであえて転置をしていません。\n\n\n数値実験\nそれでは実装した qr によって実際に行列のQR分解ができるか実験してみましょう。\nまずはWikipediaに載っている例を元に実験してみます。\n\n{-# LANGUAGE DataKinds #-}\n\ndo\n  let x = fromJust $ fromList\n            [ [12, -51,   4]\n            , [ 6, 167, -68]\n            , [-4,  24, -41]]\n            :: Matrix 3 3 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n   0.857  -0.394  -0.331\n   0.429   0.903   0.034\n  -0.286   0.171  -0.943\nR = \n  14.000  21.000 -14.000\n   0.000 175.000 -70.000\n   0.000   0.000  35.000\nQR = \n  12.000 -51.000   4.000\n   6.000 167.000 -68.000\n  -4.000  24.000 -41.000\nQ^TQ =\n   1.000   0.000   0.000\n   0.000   1.000   0.000\n   0.000   0.000   1.000\n\n\nWolframAlphaでも同様の計算を行った結果と比べてみても値が一致していることが分かります。\n次に非正則行列の場合を見てみましょう。先程の例の行ベクトルと列ベクトルを一つずつ0に変えたような行列を使って実験してみます。\n\ndo\n  let x = fromJust $ fromList\n            [ [ 0,   0,   0]\n            , [ 6, 167,   0]\n            , [-4,  24,   0]]\n            :: Matrix 3 3 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n  -0.000  -0.000   1.000\n   0.832   0.555   0.000\n  -0.555   0.832   0.000\nR = \n   7.211 125.640   0.000\n  -0.000 112.604   0.000\n  -0.000   0.000   0.000\nQR = \n  -0.000  -0.000   0.000\n   6.000 167.000   0.000\n  -4.000  24.000   0.000\nQ^TQ =\n   1.000   0.000  -0.000\n   0.000   1.000   0.000\n  -0.000   0.000   1.000\n\n\n問題なさそうですね。\n次に非正方行列の場合を見てみましょう。\n\ndo\n  let x = fromJust $ fromList\n            [ [12, -51]\n            , [ 6, 167]\n            , [-4,  24]]\n            :: Matrix 3 2 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n   0.857  -0.394   0.331\n   0.429   0.903  -0.034\n  -0.286   0.171   0.943\nR = \n  14.000  21.000\n   0.000 175.000\n  -0.000   0.000\nQR = \n  12.000 -51.000\n   6.000 167.000\n  -4.000  24.000\nQ^TQ =\n   1.000   0.000  -0.000\n   0.000   1.000  -0.000\n  -0.000  -0.000   1.000\n\n\n\ndo\n  let x = fromJust $ fromList\n            [ [12, -51,   4]\n            , [ 6, 167, -68]]\n            :: Matrix 2 3 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n   0.894  -0.447\n   0.447   0.894\nR = \n  13.416  29.069 -26.833\n  -0.000 172.177 -62.610\nQR = \n  12.000 -51.000   4.000\n   6.000 167.000 -68.000\nQ^TQ =\n   1.000   0.000\n   0.000   1.000\n\n\n行より列が多い場合でも列より行が多い場合でも問題なく計算できています。"
  },
  {
    "objectID": "posts/2024-10-12/index.html",
    "href": "posts/2024-10-12/index.html",
    "title": "行列式がフィボナッチ数列になる行列",
    "section": "",
    "text": "フィボナッチ数列\n\\[\n1, 2, 3, 5, 8, 13, 21, \\dots\n\\]\nの第n項を \\(F_n\\) と置くと、\\(i\\) を純虚数として \\(i, 1, i\\) が並ぶ以下のような \\(n\\times n\\) の三重対角行列の行列式は \\(F_n\\) に一致します。\n\\[\n\\left|\\begin{matrix}\n1 & i &        &        &   \\\\\ni & 1 & i      &        &   \\\\\n  & i & \\ddots & \\ddots &   \\\\\n  &   & \\ddots & \\ddots & i  \\\\\n  &   &        & i      & 1\n\\end{matrix}\\right| = F_n\n\\]\n行列の数字が書かれていない要素は0です。まずはこの事実を計算して確かめてみましょう。"
  },
  {
    "objectID": "posts/2024-10-12/index.html#行列式の余因子展開",
    "href": "posts/2024-10-12/index.html#行列式の余因子展開",
    "title": "行列式がフィボナッチ数列になる行列",
    "section": "行列式の余因子展開",
    "text": "行列式の余因子展開\n本稿では行列の実装として二重リストを使用します。\n\n-- 行列\ntype Matrix a = [[a]]\n\n後々必要になるので、先に行列を整形して表示する関数も用意しておきましょう。\n\nimport Data.List (intercalate)\n\n-- | 行列を整形して表示する\ndisplayM :: Show a =&gt; Matrix a -&gt; IO ()\ndisplayM = putStrLn . intercalate \"\\n\" . map (unwords . map show)\n\n行列式を効率よく計算するにはLU分解を使用するのが良いですが、今回はシンプルに行列式の余因子展開を使って再帰的に計算します。\n\n-- 行列式\ndet :: Num a =&gt; Matrix a -&gt; a\ndet [[x]] = x\ndet xss = foldr1 (-) (zipWith (*) col1 (map det (minors cols)))\n  where\n    col1 = map head xss\n    cols = map tail xss\n\n-- | 与えられたリストから要素を一つ除いたリストのリストを生成する\n-- | &gt;&gt;&gt; minors [1,2,3,4]\n-- [[2,3,4],[1,3,4],[1,2,4],[1,2,3]]\nminors :: [a] -&gt; [[a]]\nminors []     = []\nminors (x:xs) = xs : map (x:) (minors xs)\n\nこちらの実装は『関数プログラミング 珠玉のアルゴリズムデザイン』で紹介されているものを元にしており、同書の「行列式の3つの計算法」という章では他にも面白い行列式の計算方法が解説されているので気になる人はぜひ読んでみてください。\n簡単な例で実際に行列式が計算できることを確かめてみましょう。\n\ndet [[1, 2], [3, 4]]\n\n-2\n\n\n\\(1\\times 4 - 2\\times 3 = -2\\) なので正解ですね。\n次に行列式がフィボナッチ数列となる行列を生成する関数を実装しましょう。\nまずは複素数を用意します。\n\nimport Data.Complex\n\n-- | 複素数\ntype C = Complex Float\n\n-- | 純虚数\ni :: C \ni = 0.0 :+ 1.0\n\n\\(i, 1, i\\) が並ぶような \\(n\\times n\\) の三重対角行列を生成する関数 fibM を実装します。\n\n-- 行列式がフィボナッチ数列となるn次行列\nfibM :: Int -&gt; Matrix C\nfibM 1 = [[1.0]]\nfibM n =\n  let fibM' = fibM (n-1)\n   in (1.0 : i : replicate (n-2) 0) : (i : head fibM') : map (0:) (tail fibM')\n\n実際に想定通りの行列が生成されているか確認してみましょう\n\ndisplayM (fibM 2)\n\n1.0 :+ 0.0 0.0 :+ 1.0\n0.0 :+ 1.0 1.0 :+ 0.0\n\n\n\ndisplayM (fibM 3)\n\n1.0 :+ 0.0 0.0 :+ 1.0 0.0 :+ 0.0\n0.0 :+ 1.0 1.0 :+ 0.0 0.0 :+ 1.0\n0.0 :+ 0.0 0.0 :+ 1.0 1.0 :+ 0.0\n\n\n\ndisplayM (fibM 4)\n\n1.0 :+ 0.0 0.0 :+ 1.0 0.0 :+ 0.0 0.0 :+ 0.0\n0.0 :+ 1.0 1.0 :+ 0.0 0.0 :+ 1.0 0.0 :+ 0.0\n0.0 :+ 0.0 0.0 :+ 1.0 1.0 :+ 0.0 0.0 :+ 1.0\n0.0 :+ 0.0 0.0 :+ 0.0 0.0 :+ 1.0 1.0 :+ 0.0\n\n\n少し目がチカチカしますがうまく行ってますね！\nそれではこれらの行列の行列式を計算してみましょう。\n\nmapM_ (print . det . fibM) [1..10]\n\n1.0 :+ 0.0\n2.0 :+ 0.0\n3.0 :+ 0.0\n5.0 :+ 0.0\n8.0 :+ 0.0\n13.0 :+ 0.0\n21.0 :+ 0.0\n34.0 :+ 0.0\n55.0 :+ 0.0\n89.0 :+ 0.0\n\n\n実際にフィボナッチ数列が得られることが確認できました！"
  },
  {
    "objectID": "posts/2024-10-12/index.html#証明",
    "href": "posts/2024-10-12/index.html#証明",
    "title": "行列式がフィボナッチ数列になる行列",
    "section": "証明",
    "text": "証明\nなぜこのような行列の行列式でフィボナッチ数列が現れるのでしょうか？いくつか具体的に計算して考えてみましょう。\nまず2次の行列の場合\n\\[\n\\left|\\begin{matrix}\n1 & i\\\\\ni & 1\\\\\n\\end{matrix}\\right|\n\\]\n行列式は \\(1\\times 1 - i\\times i = 2\\) で確かに\\(F_2\\)になります。\n次に3次の行列の場合\n\\[\n\\left|\\begin{matrix}\n1 & i & 0\\\\\ni & 1 & i\\\\\n0 & i & 1\\\\\n\\end{matrix}\\right|\n\\]\n1行目を使って行列式の余因子展開を考えると、行列式は\n\\[\n1\\times\\left|\\begin{matrix}\n1 & i\\\\\ni & 1\\\\\n\\end{matrix}\\right|\n-i\\times\\left|\\begin{matrix}\ni & i\\\\\n0 & 1\\\\\n\\end{matrix}\\right|\n= 1\\times F_2 - i\\times i = 3\n\\]\nで確かに\\(F_3\\)となります。\nそして4次の行列の場合\n\\[\n\\left|\\begin{matrix}\n1 & i & 0 & 0\\\\\ni & 1 & i & 0\\\\\n0 & i & 1 & i\\\\\n0 & 0 & i & 1\\\\\n\\end{matrix}\\right|\n\\]\n1行目を使って行列式の余因子展開を考えると、行列式は\n\\[\n1\\times\\left|\\begin{matrix}\n1 & i & 0\\\\\ni & 1 & i\\\\\n0 & i & 1\\\\\n\\end{matrix}\\right|\n-i\\left|\\begin{matrix}\ni & i & 0\\\\\n0 & 1 & i\\\\\n0 & i & 1\\\\\n\\end{matrix}\\right|\n=1\\times F_3 - i \\left(\ni\\times\\left|\\begin{matrix}\n1 & i\\\\\ni & 1\\\\\n\\end{matrix}\\right|\n-i\\times\\left|\\begin{matrix}\n0 & i\\\\\n0 & 1\\\\\n\\end{matrix}\\right|\n\\right)\n=F_3-i\\times i\\times F_2\n=F_3+F_2\n=F_4\n\\]\nでフィボナッチ数列の定義より確かに\\(F_4\\)に一致します。\nここまで確認すれば行列式がフィボナッチ数列とどのように対応しているかは明白ですね！\n実は三重対角行列の行列式は一般的に\n\\[\nf_n = \\left|\\begin{matrix}\na_1 & b_1 &        &         & \\\\\nc_1 & a_2 & b_2    &         & \\\\\n    & c_2 & \\ddots & \\ddots  & \\\\\n    &     & \\ddots & \\ddots  & b_{n-1} \\\\\n    &     &        & c_{n-1} & a_n \\\\\n\\end{matrix}\\right|\n\\]\nと置くと\n\\[\nf_n = a_nf_{n-1} - c_{n-1}b_{n-1}f_{n-2}\n\\]\nという漸化式で計算できることが知られています（参考）。フィボナッチ数列を生成する行列はこの漸化式がうまくフィボナッチ数列の漸化式になるように調整されていたんですね。\n仕組みが分かれば純虚数\\(i\\)を使わなくても、例えば以下の様な行列の行列式でフィボナッチ数列が計算できることが分かります。\n\\[\n\\left|\\begin{matrix}\n1 & -1 &        &        &   \\\\\n1 & 1  & -1     &        &   \\\\\n  & 1  & \\ddots & \\ddots &   \\\\\n  &    & \\ddots & \\ddots & -1  \\\\\n  &    &        & 1      & 1\n\\end{matrix}\\right|\n\\]\n最後のこの行列式がフィボナッチ数列と一致することを確認してみましょう。\n\nfibM2 :: Int -&gt; Matrix Int\nfibM2 1 = [[1]]\nfibM2 n =\n  let fibM2' = fibM2 (n-1)\n   in (1 : -1 : replicate (n-2) 0) : (1 : head fibM2') : map (0:) (tail fibM2')\n\n\ndisplayM (fibM2 2)\n\n1 -1\n1 1\n\n\n\ndisplayM (fibM2 3)\n\n1 -1 0\n1 1 -1\n0 1 1\n\n\n\ndisplayM (fibM2 4)\n\n1 -1 0 0\n1 1 -1 0\n0 1 1 -1\n0 0 1 1\n\n\n行列式を計算すると\n\nmapM_ (print . det . fibM2) [1..10]\n\n1\n2\n3\n5\n8\n13\n21\n34\n55\n89\n\n\nフィボナッチ数列に一致することが確認できました👏"
  },
  {
    "objectID": "posts/2020-03-29/index.html",
    "href": "posts/2020-03-29/index.html",
    "title": "高速フーリエ変換を実装してみた",
    "section": "",
    "text": "高速フーリエ変換の実装を難しそうかなと思っている方が、なんだ簡単じゃないですか！！ となるための実装講座です という記事が分かりやすかったのでHaskellでも実装してみました"
  },
  {
    "objectID": "posts/2020-03-29/index.html#離散フーリエ変換",
    "href": "posts/2020-03-29/index.html#離散フーリエ変換",
    "title": "高速フーリエ変換を実装してみた",
    "section": "離散フーリエ変換",
    "text": "離散フーリエ変換\nまずは普通のフーリエ変換を実装します\n\nimport Data.Complex\n\nfourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\nfourierTransform xs =\n  let n = length xs\n      f aj i j = aj * cis (2 * pi * fromIntegral (i * j) / fromIntegral n)\n   in flip map [0..n-1] $ \\i -&gt; foldr (\\(j, aj) -&gt; (+) (f aj i j)) 0 (zip [0..] xs)\n\ninverseFourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\ninverseFourierTransform xs =\n  let n = length xs\n      f aj i j = aj * cis (-2 * pi * fromIntegral (i * j) / fromIntegral n)\n   in flip map [0..n-1] $ \\i -&gt; foldr (\\(j, aj) -&gt; (+) (f aj i j)) 0 (zip [0..] xs) / fromIntegral n\n\n元に戻ることを確認。これは気が向いたらQuickCheckで書き直したい\n\ninverseFourierTransform $ fourierTransform [1, 2, 3, 4]\n\n[1.0000000000000002 :+ 5.551115123125783e-16,2.0 :+ 3.885780586188048e-16,3.0 :+ 5.551115123125783e-17,4.0 :+ (-3.3306690738754696e-16)]"
  },
  {
    "objectID": "posts/2020-03-29/index.html#高速フーリエ変換",
    "href": "posts/2020-03-29/index.html#高速フーリエ変換",
    "title": "高速フーリエ変換を実装してみた",
    "section": "高速フーリエ変換",
    "text": "高速フーリエ変換\n高速フーリエ変換はフーリエ変換の計算を分割して再帰的に計算するので関数型プログラミングと相性が良さそうかなと思ったけど実装は泥臭い感じになりました。うまいやり方とかあったらTwitterでこっそり教えて下さい\nあと単純な実装なので2の累乗の長さのリストでしかうまく行かないやつです。\n\nimport Control.Arrow\n\nsplitEvenOdd :: [a] -&gt; ([a], [a])\nsplitEvenOdd = (reverse *** reverse) . go ([], [])\n  where go x [] = x\n        go (xs, ys) [x] = (x:xs, ys)\n        go (xs, ys) (x:y:zs) = go (x:xs, y:ys) zs\n\nmapTuple2 :: (a -&gt; b) -&gt; (a, a) -&gt; (b, b)\nmapTuple2 f (a1, a2) = (f a1, f a2)\n\nfastFourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\nfastFourierTransform []  = error \"The length of list must be the power of 2.\"\nfastFourierTransform [x] = [x]\nfastFourierTransform xs  =\n  let n = length xs\n      (bs, cs) = mapTuple2 fastFourierTransform $ splitEvenOdd xs\n      atN2 xs i = xs !! (i `mod` (n `div` 2))\n      f i = bs `atN2` i + cs `atN2` i * cis (2 * pi * fromIntegral i / fromIntegral n)\n   in map f [0..n-1]\n\ninverseFastFourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\ninverseFastFourierTransform xs = map (/ fromIntegral (length xs)) $ ifft xs\n  where\n    ifft []  = error \"The length of list must be the power of 2.\"\n    ifft [x] = [x]\n    ifft xs  =\n      let n = length xs\n          (bs, cs) = mapTuple2 ifft $ splitEvenOdd xs\n          atN2 xs i = xs !! (i `mod` (n `div` 2))\n          f i = bs `atN2` i + cs `atN2` i * cis (-2 * pi * fromIntegral i / fromIntegral n)\n       in map f [0..n-1]\n\nこれも元に戻ることを確認\n\ninverseFastFourierTransform $ fastFourierTransform [1,2,3,4]\n\n[1.0 :+ 4.057416247971343e-16,2.0 :+ 9.385873628418619e-17,3.0 :+ 8.411709486180696e-17,4.0 :+ (-2.1632341619892149e-16)]"
  },
  {
    "objectID": "posts/2020-03-29/index.html#実験ローパスフィルタ",
    "href": "posts/2020-03-29/index.html#実験ローパスフィルタ",
    "title": "高速フーリエ変換を実装してみた",
    "section": "実験：ローパスフィルタ",
    "text": "実験：ローパスフィルタ\n実装したFFTでうまく周波数の空間に変換できてるのか確認します。低周波と高周波を合成した信号を作成し、低周波成分だけ取り出してみます。\n\nimport Graphics.Rendering.Chart.Easy\n\nsignal :: [Double]\nsignal = map (\\i -&gt; sin (2 * pi * fromIntegral i / 32) + sin (2 * pi * fromIntegral i / 512)) [1..2048]\n\ntoRenderable $ plot (line \"sigmal\" [zip [0..] signal])\n\n\n\n\n\n\n\n\n実行した高速フーリエ変換で変換して周波数空間での様子を確認\n\nfSignal :: [Complex Double]\nfSignal = fastFourierTransform $ map (:+ 0) signal\n\nfSignalR, fSignalI :: [Double]\nfSignalR = map realPart fSignal\nfSignalI = map imagPart fSignal\n\ntoRenderable $ do\n    plot (line \"fSignalR\" [zip [0..] fSignalR])\n    plot (line \"fSignalI\" [zip [0..] fSignalI])\n\n\n\n\n\n\n\n\nローパスフィルタは、フーリエ変換して先頭からN個の成分以外を0にして逆フーリエ変換するように実装する\n想定通りに低周波成分だけ取り出すことができた。なんだ簡単じゃないですか！！\n\nconsider :: Num a =&gt; Int -&gt; [a] -&gt; [a]\nconsider _ []     = []\nconsider 0 xs     = replicate (length xs) 0\nconsider n (x:xs) = x : consider (n-1) xs\n\nlowPassFilter :: Int -&gt; [Double] -&gt; [Double]\nlowPassFilter n = map realPart . inverseFastFourierTransform . consider n . fastFourierTransform . map (:+ 0)\n\nsignal' :: [Double]\nsignal' = lowPassFilter 10 signal\n\ntoRenderable $ plot (line \"signal'\" [zip [0..] signal'])\n\n\n\n\n\n\n\n\n高速フーリエ変換、完全に理解した。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "微分可能な比較演算子でライフゲームを逆算する\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2024\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\n行列式がフィボナッチ数列になる行列\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2024\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nランダムフィボナッチ数列をHaskellで実装する\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2024\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nHaskellでQR分解を実装する\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2024\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nHaskellで実装するk-means法とk-means++法\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2024\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\n高次元空間ではL1距離を使うのが良さそう\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\n2点テイラー展開の定義と数値実験\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nHaskellの非同期処理を使った入出力の重ね合わせ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJun 29, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nGHCi の :sprint が便利\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\n高速フーリエ変換を実装してみた\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2020\n\n\nlotz\n\n\n\n\n\n\nNo matching items"
  }
]