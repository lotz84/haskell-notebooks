[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "IHaskellで書いたnotebookを公開する場所\nZennにも記事を書いています\nhttps://zenn.dev/lotz"
  },
  {
    "objectID": "posts/2020-07-11/index.html",
    "href": "posts/2020-07-11/index.html",
    "title": "高次元空間ではL1距離を使うのが良さそう",
    "section": "",
    "text": "“On the Surprising Behavior of Distance Metrics in High Dimensional Spaces”という論文を読んで面白かったのでまとめておきます。\n\\(d\\)次元空間の立方体\\((0,1)^d\\)中に分布する確率変数\\(X_d\\)を考えます。例えばモノクロ画像なんかは正規化すれば今考えてる確率変数になるでしょう。今\\((0, 1)\\)上の任意の分布\\(F\\)を考え\\(F^d\\)を確率分布とする\\(X_d\\)から\\(n\\)個のサンプルが得られたとします。サンプルにおける\\(L_k\\)ノルムの最大値を\\(Dmax^k_d\\)、最小値を\\(Dmin^k_d\\)とすると、\\(F\\)と\\(k\\)のみに依存する定数\\(C_k\\)が存在して\n\\[\nC_k \\leq \\underset{d \\rightarrow \\infty}{\\lim}{\\rm E}\\left[\\frac{Dmax^k_d - Dmin^k_d}{d^{\\frac{1}{k}-\\frac{1}{2}}}\\right] \\leq (n-1)C_k\n\\]\nが成り立ちます。ここで\\({\\rm E}[X]\\)は\\(X\\)の期待値を表します。\nつまりデータの存在する次元が上がるにつれて原点に近いものと遠いものの差が変化するスピードは\\(d^{\\frac{1}{k}-\\frac{1}{2}}\\)ぐらいになるということです。証明を読めば分かりますが、差の漸近的な振る舞いを決める\\(d^{\\frac{1}{k}-\\frac{1}{2}}\\)の\\(\\frac{1}{2}\\)は中心極限定理から出てきます。もし\\(k \\geq 3\\)であればこれは減衰するので、どんどん近いデータと遠いデータの間に差がなくなってくるということを意味しています。これは原点を任意の注目する点に置き換えて考えれば、例えばサンプルの近傍を考えるときに次元が高くなると遠いものと近いものの区別がどんどんつかなくなっていくことを表しています。一方もし\\(k=2\\)であればこの差は一定に落ち着き、\\(k=1\\)であれば（期待通り？）大きくなってくれます。\n次元が高くなれば立方体の対角線の長さも大きくなるので直感的には最大値と最小値の差はどんどん大きくなっていきそうですが、同時に、すべての次元で0付近の値が出る確率や1付近の値が出る確率は次元が高くなるとどんどん小さくなるので、差の期待値がどう振る舞うかはこれらの綱引きになりそうなことは直感的には分かります。この綱引きの勝敗が距離の測り方で決まるのは面白いですね。\nこの挙動を実際に確かめてみましょう。\n\nimport Control.Monad (replicateM)\nimport System.Random.MWC\n\n\n-- | 確率変数\ntype RVar a = GenIO -&gt; IO a\n\n\n-- | n個のリストの確率変数\nrandomNs :: Int -&gt; RVar a -&gt; RVar [a]\nrandomNs n x = sample n\n  where\n    sample 0 _ = pure []\n    sample n g = do\n      a &lt;- x g\n      as &lt;- sample (n-1) g\n      pure (a:as)\n\n\n-- L_kノルム\nlk :: Int -&gt; [Double] -&gt; Double\nlk k xs = sum (map (^k) xs) ** (1.0 / fromIntegral k)\n\n\n-- | Dmax^k_d - Dmin^k_d\ndiameter :: Int -- 直径計算のためのサンプルを生成する数\n         -&gt; Int -- L_kノルムのk\n         -&gt; Int -- 次元d\n         -&gt; RVar Double\ndiameter n k d g =\n  let xs g = replicateM d (uniformR (0.0, 1.0) g)\n   in do\n     xss &lt;- randomNs n xs g\n     let ds = map (lk k) xss\n     pure $ maximum ds - minimum ds\n\n\n-- | 確率変数の期待値\nexpected :: Fractional a\n         =&gt; Int    -- 期待値を計算するのに用いるサンプル数\n         -&gt; RVar a -- 期待値を求める確率変数\n         -&gt; RVar a -- 期待値の確率変数\nexpected n x g = do\n  as &lt;- randomNs n x g\n  pure $ sum as / fromIntegral n\n\n\nimport Data.Traversable (forM)\nimport Graphics.Rendering.Chart.Easy\n\nds :: [Int]\nds = [1..50]\n\nwithSystemRandom $ \\gen -&gt; do\n  diff1 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 1 d) gen\n  diff2 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 2 d) gen\n  diff3 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 3 d) gen\n  diff4 &lt;- forM ds $ \\d -&gt; expected 100 (diameter 100 4 d) gen\n  pure . toRenderable $ do\n      plot (line \"k = 1\" [zip ds diff1])\n      plot (line \"k = 2\" [zip ds diff2])\n      plot (line \"k = 3\" [zip ds diff3])\n      plot (line \"k = 4\" [zip ds diff4])\n\n\n\n\n\n\n\n\n次元を増やすにつれて\\(k=1\\)の時は最小値と最大値の差が大きくなっていきますが、\\(k=2\\)の場合は一定に落ち着き、\\(k=3,4\\)の場合は差がどんどんなくなっていき、この傾向は\\(k\\)が大きければより強いことが分かります。\n論文ではもう一つ面白い式が導かれています。先程の不等式は最大値と最小値の差についてでしたが、今度は比についてです。\n\\[\n\\underset{d \\rightarrow \\infty}{\\lim} {\\rm E}\\left[\\sqrt{d}\\left(\\frac{Dmax^k_d}{Dmin^k_d} - 1\\right)\\right] = C\\sqrt{\\frac{1}{2k+1}}\n\\]\nただしこの式は\\(F\\)が一様分布でサンプルが2点である時という制約がついています。この式が示唆するのは最大値と最小値の比は\\(\\frac{1}{\\sqrt{d}}\\)ぐらいのスピードで1に近づいていくということで、この挙動は\\(k\\)が1,2のときでも変わりません。"
  },
  {
    "objectID": "posts/2020-06-29/index.html",
    "href": "posts/2020-06-29/index.html",
    "title": "Haskellの非同期処理を使った入出力の重ね合わせ",
    "section": "",
    "text": "これは『Haskellによる並列・並行プログラミング』リモート輪講 #10の発表資料です。\nHaskellの非同期処理を使って並行に入出力を伴う処理を行うプログラムを書く方法について見ていきます。まず、複数のWebページを並行にダウンロードするようなタスクを考えます\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls1.hs\n\nimport Control.Concurrent\nimport Data.ByteString.Char8 as B\nimport System.Random\n\ngetURL :: String -&gt; IO ByteString\ngetURL url = do\n  delay &lt;- randomRIO (500000, 1500000) -- URLのコンテンツを取得する時間ということにする\n  threadDelay delay\n  pure (B.pack url)\n\nexample1 :: IO ()\nexample1 = do\n  m1 &lt;- newEmptyMVar\n  m2 &lt;- newEmptyMVar\n  \n  forkIO $ do\n    r &lt;- getURL \"https://en.wikipedia.org/wiki/Shovel\"\n    putMVar m1 r\n\n  forkIO $ do\n    r &lt;- getURL \"https://en.wikipedia.org/wiki/Spade\"\n    putMVar m2 r\n\n  r1 &lt;- takeMVar m1\n  r2 &lt;- takeMVar m2\n  print (B.length r1, B.length r2)\nという共通する実装のパターンが見え隠れしているので共通化してみましょう\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls2.hs\n\nnewtype Async a = Async (MVar a)\n\nasync :: IO a -&gt; IO (Async a)\nasync action = do\n  var &lt;- newEmptyMVar\n  forkIO (action &gt;&gt;= putMVar var)\n  pure (Async var)\n\nwait :: Async a -&gt; IO a\nwait (Async var) = readMVar var\n意図しないデッドロックを防ぐために wait では takeMVar ではなく readMVar を使っています\nこれを使えば example1 を以下のように書き換えることができます\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls2.hs\n\nexample2 :: IO ()\nexample2 = do\n  a1 &lt;- async (getURL \"https://en.wikipedia.org/wiki/Shovel\")\n  a2 &lt;- async (getURL \"https://en.wikipedia.org/wiki/Spade\")\n  r1 &lt;- wait a1\n  r2 &lt;- wait a2\n  print (B.length r1, B.length r2)\n\nexample2\n\n(36,35)\nモナディックなコンビネータを使って更に簡潔に書くことも可能です\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls3.hs\n\nsites =\n  [ \"http://www.google.com\"\n  , \"http://www.bing.com\"\n  , \"http://www.yahoo.com\"\n  , \"http://www.wikipedia.com/wiki/Spade\"\n  , \"http://www.wikipedia.com/wiki/Shovel\"\n  ]\n\nexample3 :: IO ()\nexample3 = do\n  as &lt;- mapM (async . getURL) sites\n  result &lt;- mapM wait as\n  print $ fmap B.length result\n\nexample3\n\n[21,19,20,35,36]"
  },
  {
    "objectID": "posts/2020-06-29/index.html#asyncでのエラー処理",
    "href": "posts/2020-06-29/index.html#asyncでのエラー処理",
    "title": "Haskellの非同期処理を使った入出力の重ね合わせ",
    "section": "Asyncでのエラー処理",
    "text": "Asyncでのエラー処理\ngetURL の中でエラーが起こった場合の挙動を見てみましょう\n\nimport Control.Exception\n\ngetURL' :: String -&gt; IO ByteString\ngetURL' url = do\n  throwIO (ErrorCall \"oops!\")\n  pure (B.pack url)\n\nexample4 :: IO ()\nexample4 = do\n  as &lt;- mapM (async . getURL') sites\n  result &lt;- mapM wait as\n  print $ fmap B.length result\n\nexample4\n\n: \n\n\ngetURL' では async の中で putMVar が実行される前に例外が投げられてしまうので wait における readMVar が永遠にスレッドをブロックしてしまいます\nこれを安全な挙動に変えるために Async 周りの実装を修正してみしましょう\n\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls4.hs\n\nnewtype Async a = Async (MVar (Either SomeException a))\n\nasync :: IO a -&gt; IO (Async a)\nasync action = do\n  var &lt;- newEmptyMVar\n  forkIO (try action &gt;&gt;= putMVar var)\n  pure (Async var)\n\nwaitCatch :: Async a -&gt; IO (Either SomeException a)\nwaitCatch (Async var) = readMVar var\n\nwait :: Async a -&gt; IO a\nwait a = do\n  r &lt;- waitCatch a\n  case r of\n    Left e  -&gt; throwIO e\n    Right a -&gt; pure a\n\nasync と wait は以前のものと同じ型ですが、例外を適切に伝搬する仕組みを備えています\n\nexample5 :: IO ()\nexample5 = do\n  as &lt;- mapM (async . getURL') sites\n  result &lt;- mapM wait as\n  print $ fmap B.length result\n\nexample5\n\n: \n\n\n最初に非同期処理が例外を投げた時点でプログラム全体が停止しているのが分かります"
  },
  {
    "objectID": "posts/2020-06-29/index.html#非同期処理の合流",
    "href": "posts/2020-06-29/index.html#非同期処理の合流",
    "title": "Haskellの非同期処理を使った入出力の重ね合わせ",
    "section": "非同期処理の合流",
    "text": "非同期処理の合流\nここでは並行に実行している非同期処理のどれか一つでも結果を返した時点で何らかの処理を行いたいような場合について見ていきます。\n以下の例は並行に複数のWebサイトをダウンロードして\n\n最初にダウンロードが完了したWebサイトの情報を表示する\n残りのダウンロードが完了するのを待つ\n\nという挙動を実装しています。\n\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls5.hs\n\nimport Control.Monad\n\nexample6 :: IO ()\nexample6 = do\n  m &lt;- newEmptyMVar\n  let download url = do\n        r &lt;- getURL url\n        putMVar m (url, r)\n\n  mapM_ (forkIO . download) sites\n  \n  (url, r) &lt;- takeMVar m\n  print $ url ++ \": \" ++ show (B.length r)\n  replicateM_ 4 (takeMVar m)\n\n-- 実行するたびに結果が変わる\nexample6\n\n\"http://www.wikipedia.com/wiki/Shovel: 36\"\n\n\nこれを明示的に MVar を用いずに Async を使って実装する事を考えましょう。\n以下の waitEither は2つの Async を受け取って最初に完了した値を IO で返す関数です。\n\nwaitEither :: Async a -&gt; Async b -&gt; IO (Either a b)\nwaitEither a b = do\n  m &lt;- newEmptyMVar\n  forkIO $ try (fmap Left  (wait a)) &gt;&gt;= putMVar m\n  forkIO $ try (fmap Right (wait b)) &gt;&gt;= putMVar m\n  wait (Async m)\n\nこの仕組は複数の Async のリストにも拡張することができます\n\nwaitAny :: [Async a] -&gt; IO a\nwaitAny as = do\n  m &lt;- newEmptyMVar\n  let forkwait a = forkIO $ try (wait a) &gt;&gt;= putMVar m\n  mapM_ forkwait as\n  wait (Async m)\n\n\n-- 勉強会中に逆に全てのAsyncを待つようなコンビネータが作れるか？という質問があったので実装してみた例\nwaitAll :: [Async a] -&gt; IO [a]\nwaitAll = mapM wait\n\n以上の実装を使って example6 は明示的に MVar を使わない形で書き換えることができます。\n\n-- https://github.com/simonmar/parconc-examples/blob/master/geturls6.hs\n\nexample7 :: IO ()\nexample7 = do\n  let download url = do\n        r &lt;- getURL url\n        pure (url, r)\n\n  as &lt;- mapM (async . download) sites\n  \n  (url, r) &lt;- waitAny as\n  \n  print $ url ++ \": \" ++ show (B.length r)\n  mapM_ wait as\n\nexample7\n\n\"http://www.wikipedia.com/wiki/Spade: 35\""
  },
  {
    "objectID": "posts/2024-05-12/index.html",
    "href": "posts/2024-05-12/index.html",
    "title": "HaskellでQR分解を実装する",
    "section": "",
    "text": "QR分解は与えられた\\(m\\times n\\)行列\\(A\\)を\\(m\\times m\\)のユニタリ行列（実数の場合、直交行列）\\(Q\\)と\\(m\\times n\\)の上三角行列\\(R\\)の積、すなわち\\(A=QR\\)と分解する手法です。 数値的に安定な計算アルゴリズムが知られており、固有値の計算（QR法）やカルマンフィルターの安定的な計算にも応用されています。またこういった分解はより抽象的な対象で考えられることも多く、QR分解は半単純リー群の岩澤分解に一般化されることが知られています。\nQR分解を実現するアルゴリズムはWikipediaにも詳しく載っており\n\nグラム・シュミットの正規直交化法\nハウスホルダー変換\nギブンス回転\n\nを利用した手法などがあります。\nHaskellでも例えば hmatrix が qr というQR分解を行う関数を提供していたり、hmatrixを使ったギブンス回転やハウスホルダー変換によるQR分解の実装を解説した記事もあります（お気楽 Haskell プログラミング入門 線形代数編）。しかし本稿ではあえて vector-sized を使って自分で実装してみようと思い、数値的にも安定しているハウスホルダー変換を利用した実行列のQR分解の実装したいと思います。\n\n即席線形代数\nまずは Haskellで実装する即席線形代数 を参考に実装に必要なベクトルと行列の型と関数の定義を行います。\n\nimport GHC.TypeLits\nimport Text.Printf\n\nimport Data.Vector.Sized (Vector)\nimport qualified Data.Vector.Sized as V\n\ntype Matrix m n a = Vector m (Vector n a)\n\n-- | ベクトルのスカラー倍\n(*^) :: Num a =&gt; a -&gt; Vector n a -&gt; Vector n a\n(*^) a = V.map (*a)\n\n-- | ベクトルをスカラー値で割る\n(^/) :: Fractional a =&gt; Vector n a -&gt; a -&gt; Vector n a\n(^/) v a = recip a *^ v\n\n-- | 内積\ndot :: Num a =&gt; Vector n a -&gt; Vector n a -&gt; a\ndot = (V.sum .) . V.zipWith (*)\n\n-- | 外積\nouter :: Num a =&gt; Vector m a -&gt; Vector n a -&gt; Matrix m n a\nouter xs ys = V.map (\\x -&gt; V.map (*x) ys) xs\n\n-- | ユークリッドノルム\nnorm2V :: Floating a =&gt; Vector n a -&gt; a\nnorm2V = sqrt . V.sum . V.map (^2)\n\n-- | リストから行列を作成する\nfromList :: (KnownNat m, KnownNat n) =&gt; [[a]] -&gt; Maybe (Matrix m n a)\nfromList = (=&lt;&lt;) V.fromList . mapM V.fromList\n\n-- | 行列を整形して表示する\ndisplayM :: PrintfArg a\n         =&gt; Int  -- 数値の表示幅\n         -&gt; Int  -- 有効数字\n         -&gt; Matrix n m a\n         -&gt; IO ()\ndisplayM w p = putStrLn . drop 1 . V.foldl (\\x v -&gt; x ++ '\\n' : V.foldl (++) \"\" (V.map (printf \"%*.*f\" w p) v)) \"\"\n\n-- | 単位行列\nidentity :: (KnownNat n, Num a) =&gt; Matrix n n a\nidentity = V.generate (\\x -&gt; V.generate (\\y -&gt; if x == y then 1 else 0))\n\n-- | 行列のスカラー倍\n(*!!) :: Num a =&gt; a -&gt; Matrix m n a -&gt; Matrix m n a\n(*!!) a = V.map (V.map (*a))\n\n-- | 行列の転置\ntranspose :: KnownNat n =&gt; Matrix m n a -&gt; Matrix n m a\ntranspose = sequenceA\n\n-- | 行列積\n(!*!) :: (KnownNat r, Num a) =&gt; Matrix m n a -&gt; Matrix n r a -&gt; Matrix m r a\na !*! b = fmap (flip fmap (transpose b) . dot) a\n\n\n\nハウスホルダー変換\nハウスホルダー変換は与えられたベクトル\\(x\\)を単位法線ベクトル\\(v\\)で表された原典を通る超平面で鏡映変換する変換です。変換後のベクトルは \\(x - 2 v \\langle v, x \\rangle\\) と表すことができ、これは行列 \\(I - 2vv^{\\rm T}\\)を\\(x\\)に左から掛けて変換していると考えることもできます。このハウスホルダー変換を使えば、与えられた行列の列ベクトルを左から順番に第n成分までの部分空間に射影していくことでQR分解を得ることができます。\nアルゴリズムの詳しい解説は他の記事に譲るとして（例えばWikipedia）、さっそく実装を見ていきたいと思います。以下 householder として実装するのは添字\\(i\\)とベクトル\\(x\\)が与えられた時に、\\(x\\)の第\\(i\\)成分以降を第\\(i\\)成分までの部分空間に射影する（すなわち残りの成分を0にする）ハウスホルダー変換を表す行列を計算する関数です。\n\nimport Data.Maybe (fromJust)\n\nimport Data.Finite (Finite)\nimport qualified Data.Vector as V'\n\n-- | ハウスホルダー変換\nhouseholder :: (KnownNat n, Ord a, Floating a) =&gt; Finite n -&gt; Vector n a -&gt; Matrix n n a\nhouseholder i' x =\n  let i = fromIntegral i'\n      y = V'.drop i $ V.fromSized x\n      u = y V'.// [(0, V'.head y - y `V.withSized` norm2V)]\n      padding = (V'.++) (V'.replicate i 0)\n      u_norm = u `V.withSized` norm2V\n      v = fromJust . V.toSized . padding $ V'.map (/u_norm) u\n   in if abs u_norm &lt; 1e-12 then identity else identity - 2 *!! outer v v\n\nベクトルと行列の型にはサイズに関する情報を持たせていますが householder では最初からその情報を捨てて素の Data.Vector で変換を行っています。理由としてはハウスホルダー変換を計算するベクトルの長さ（すなわち型）は第一引数である i' の値に依存しており、今のHaskellの依存型だと今回の様な状況では簡潔に実装できる方法がないため型からサイズの情報を削ることにしました。\n実装中に単位法線ベクトル\\(v\\)を計算するために法線ベクトル\\(u\\)をそのノルムで割る処理がありますが、\\(u\\)のノルムが非常に小さい場合この処理は不安定になります。しかし\\(u\\)のノルムが非常に小さいということは\\(x\\)と変換後のベクトルがほぼ等しいという状況を表しており、このような場合には結果となる変換行列をただの単位行列にするようにしています。\n\n\nQR分解\nQR分解は与えられた行列の列ベクトルを左から順番にハウスホルダー変換して上三角行列を作ることにより得ることができます。\n\n{-# LANGUAGE ScopedTypeVariables #-}\n\nimport Data.Proxy\n\nimport Data.Finite (finite)\n\nqr :: forall m n a. (KnownNat m, KnownNat n, Ord a, Floating a) =&gt; Matrix m n a -&gt; (Matrix m m a, Matrix m n a)\nqr a =\n  transpose &lt;$&gt;\n    foldl (\\(q, r) i -&gt;\n      let p = householder (finite i) (V.index r (finite i))\n       in (q !*! p, r !*! p)\n    ) (identity, transpose a) [0..k-1]\n  where k = fromInteger $ min (natVal (Proxy @n)) (natVal (Proxy @m))\n\n実装上の都合で行列は行ベクトルのベクトルとなっているので、列ベクトルを扱うために最初に転置を行い\\(A^{\\rm T}\\)、得られた\\(R^{\\rm T}\\)を最後にもう一度転置することにより計算しています。\\(Q\\)については本来転置したものが計算結果になるのであえて転置をしていません。\n\n\n数値実験\nそれでは実装した qr によって実際に行列のQR分解ができるか実験してみましょう。\nまずはWikipediaに載っている例を元に実験してみます。\n\n{-# LANGUAGE DataKinds #-}\n\ndo\n  let x = fromJust $ fromList\n            [ [12, -51,   4]\n            , [ 6, 167, -68]\n            , [-4,  24, -41]]\n            :: Matrix 3 3 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n   0.857  -0.394  -0.331\n   0.429   0.903   0.034\n  -0.286   0.171  -0.943\nR = \n  14.000  21.000 -14.000\n   0.000 175.000 -70.000\n   0.000   0.000  35.000\nQR = \n  12.000 -51.000   4.000\n   6.000 167.000 -68.000\n  -4.000  24.000 -41.000\nQ^TQ =\n   1.000   0.000   0.000\n   0.000   1.000   0.000\n   0.000   0.000   1.000\n\n\nWolframAlphaでも同様の計算を行った結果と比べてみても値が一致していることが分かります。\n次に非正則行列の場合を見てみましょう。先程の例の行ベクトルと列ベクトルを一つずつ0に変えたような行列を使って実験してみます。\n\ndo\n  let x = fromJust $ fromList\n            [ [ 0,   0,   0]\n            , [ 6, 167,   0]\n            , [-4,  24,   0]]\n            :: Matrix 3 3 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n  -0.000  -0.000   1.000\n   0.832   0.555   0.000\n  -0.555   0.832   0.000\nR = \n   7.211 125.640   0.000\n  -0.000 112.604   0.000\n  -0.000   0.000   0.000\nQR = \n  -0.000  -0.000   0.000\n   6.000 167.000   0.000\n  -4.000  24.000   0.000\nQ^TQ =\n   1.000   0.000  -0.000\n   0.000   1.000   0.000\n  -0.000   0.000   1.000\n\n\n問題なさそうですね。\n次に非正方行列の場合を見てみましょう。\n\n{-# LANGUAGE DataKinds #-}\n\ndo\n  let x = fromJust $ fromList\n            [ [12, -51]\n            , [ 6, 167]\n            , [-4,  24]]\n            :: Matrix 3 2 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n   0.857  -0.394   0.331\n   0.429   0.903  -0.034\n  -0.286   0.171   0.943\nR = \n  14.000  21.000\n   0.000 175.000\n  -0.000   0.000\nQR = \n  12.000 -51.000\n   6.000 167.000\n  -4.000  24.000\nQ^TQ =\n   1.000   0.000  -0.000\n   0.000   1.000  -0.000\n  -0.000  -0.000   1.000\n\n\n\n{-# LANGUAGE DataKinds #-}\n\ndo\n  let x = fromJust $ fromList\n            [ [12, -51,   4]\n            , [ 6, 167, -68]]\n            :: Matrix 2 3 Double\n      (q, r) = qr x\n  putStrLn \"Q = \"\n  displayM 8 3 q\n  putStrLn \"R = \"\n  displayM 8 3 r\n  putStrLn \"QR = \"\n  displayM 8 3 $ q !*! r\n  putStrLn \"Q^TQ =\"\n  displayM 8 3 $ transpose q !*! q\n\nQ = \n   0.894  -0.447\n   0.447   0.894\nR = \n  13.416  29.069 -26.833\n  -0.000 172.177 -62.610\nQR = \n  12.000 -51.000   4.000\n   6.000 167.000 -68.000\nQ^TQ =\n   1.000   0.000\n   0.000   1.000\n\n\n行より列が多い場合でも列より行が多い場合でも問題なく計算できています。"
  },
  {
    "objectID": "posts/2020-07-09/index.html",
    "href": "posts/2020-07-09/index.html",
    "title": "2点テイラー展開の定義と数値実験",
    "section": "",
    "text": "テイラー展開は滑らかな関数の一点における値や微分の値を使ったべき級数によって元の関数を表す方法でした。\n\\[\nf(x) = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2!}\\left(x-a\\right)^2 + \\frac{f'''(a)}{3!}\\left(x-a\\right)^3 + \\cdots\n\\]\nこれを2点以上に拡張したテイラー展開が存在していて、特に2点でテイラー展開を行うものは2点テイラー展開と呼ばれているそうです。\nなんで2点でテイラー展開したくなるのかというと、普通のテイラー展開だと1点における2n階までの微分値を使わないと達成できない近似精度を2点テイラー展開だと2点におけるn階までの微分値で達成できたりするそうなのですが（スゴイ！）[^1]、個人的には2点でテイラー展開することで区分的に定義された関数も近似できるのが面白いなと思いました。\nテイラー展開は1点の周りにおける情報しか使わないので通常近似できる範囲はその1点の近くまでです。特に関数が折れ線だったり、ReLUのように各領域によって違う関数の組み合わせで表されている場合には領域を区分する点をまたいで近似できる範囲を拡張することができません。そこで2点テイラー展開を使えば区分する点をまたいだ2点の周りで展開することによりそれぞれの点の周りの情報を使ってテイラー展開よりも近似できる範囲を拡張することができるのです。以下の定理はこのことをより正確に表しています[^2]。\nTheorem. \\(f\\)を\\({\\mathbb R}\\)上の以下のように表される関数とする。\n\\[\nf(x) = \\begin{cases} p(x)\\ \\ x \\in [0, \\infty) \\\\ q(x)\\ \\ x \\in (-\\infty, 0) \\end{cases}\n\\]\nここで\\(p, q\\)は高々\\(m\\)次の多項式とする。この時、もし\\(p(0)=q(0)\\)であるならば\\(f(x)\\)は-1, 1において2点テイラー展開可能であり、\\(p_{f,\\{-1, 1\\}(n, n)}(x)\\)をエルミート補間多項式だとすると以下が成り立つ。\n\\[\n\\underset{n \\rightarrow \\infty}{\\lim}p_{f,\\{-1, 1\\}(n, n)}(x)=f(x), \\forall x \\in \\left(-\\sqrt 2, \\sqrt 2\\right)\n\\]\nところでまだ2点テイラー展開の定義をしていませんでした。2点テイラー展開は多項式補間の考え方を経由して定義されます。\n（以下の説明は[^2]の導入部分を大いに参考にしています）\n十分になめらかな実数値関数\\(f(x)\\)に対して\\(n\\)個の点\\(X = \\{x_0,\\dots,x_n\\}\\)とそれぞれの点に対応する自然数\\(k_i(0\\leq i\\leq n)\\)が与えられた時、高々\\(m(=k_0+\\cdots+k_n-1)\\)次の多項式\\(p_{f,X(k_0,\\dots,k_n)}(x)\\)が存在して\n\\[\np^{(j)}_{f,X(k_0,\\dots,k_n)}(x_i) = f^{(j)}(x_i), 0\\leq j \\leq k_i-1, 0 \\leq i \\leq n\n\\]\nを満たす時、\\(p_{f,X(k_0,\\dots,k_n)}(x)\\)を\\(f(x)\\)のエルミート補間多項式と呼びます。\nもし\\(f(x)\\)が一点\\(x_0\\)の周りで無限回微分可能であり、ある正の実数\\(\\rho\\)が存在して\n\\[\n\\underset{n \\rightarrow \\infty}{\\lim} p_{f,X(n)}(x) = f(x), \\forall x \\in (x_0-\\rho, x_0+\\rho)\n\\]\nとなるならば\\(f(x)\\)は同じ範囲でテイラー展開可能であることが分かります。\nこの事実を発展させて\\(n\\)点テイラー展開は以下のように定義されます。\n\\(f\\)をある区間\\(I\\)で定義された実数値関数とし、\\(I\\)に含まれる\\(n\\)個の点\\(X=\\{x_0,\\dots x_{n-1}\\}\\)で\\(f\\)が無限回微分可能であったとする。もし\n\\[\n\\underset{m \\rightarrow \\infty}{\\lim} p_{f,X(m,\\dots,m)}(x) = f(x), \\forall x \\in I\n\\]\nが成り立つならば\\(f\\)は\\(I\\)において\\(n\\)点テイラー展開可能であるという。\n\\(n\\)点テイラー展開の具体的な形は、エルミート補間多項式の一般公式が知られているので[^3]そちらから計算可能でしょう。特に2点テイラー展開の場合の級数の計算式は以下のようにできるとTwitterで教えてもらいました[^4]。（そもそも2点テイラー展開を知ったきっかけも、このnotebookを書こうと思ったのも島田さんのTweetに触発されてでした。感謝🙏）"
  },
  {
    "objectID": "posts/2020-07-09/index.html#数値実験",
    "href": "posts/2020-07-09/index.html#数値実験",
    "title": "2点テイラー展開の定義と数値実験",
    "section": "数値実験",
    "text": "数値実験\n比較のためにまずは通常のテイラー展開を実装してみます\n\n{-# LANGUAGE RankNTypes #-}\n\nimport Data.Number.Symbolic\n\nimport Numeric.AD\nimport Numeric.AD.Mode.Tower\n\n\n-- 階乗\nfact :: Int -&gt; Int\nfact n = product [1..n]\n\n\n-- テイラー展開\ntaylorSeries :: Fractional a\n             =&gt; Int                                          -- この次数以下の級数まで展開する\n             -&gt; (forall s. AD s (Tower a) -&gt; AD s (Tower a)) -- テイラー展開する関数\n             -&gt; a                                            -- 展開する点\n             -&gt; (a -&gt; a)                                     -- 展開後の級数\ntaylorSeries n f a x = sum $ take n $ coefficients |*| polynomials\n  where\n  coefficients = diffs f a |/| factorials      -- f(a)/0!, f'(a)/1!, f''(a)/2!, f'''(a)/3!, ...\n  factorials = map (fromIntegral . fact) [0..] -- 0!, 1!, 2!, 3!, ...\n  polynomials = ((x - a)^) &lt;$&gt; [0..]           -- 1, x-a, (x-a)^2, (x-a)^3, ...\n  (|/|) = zipWith (/)\n  (|*|) = zipWith (*)\n\n\ntaylorSeries 4 exp 0 (var \"x\")\n\n1.0+x+0.5*x*x+0.16666666666666666*x*x*x\n\n\n4次までの指数関数のテイラー展開をちゃんと計算できていますね\n\\[\n1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!}\n\\]\n次は2点テイラー展開を実装してみましょう\n\n-- 2点テイラー展開\ntwoPointTaylorSeries :: Fractional a\n                     =&gt; Int                                          -- この次数以下の級数まで展開する\n                     -&gt; (forall s. AD s (Tower a) -&gt; AD s (Tower a)) -- テイラー展開する関数\n                     -&gt; a                                            -- 展開する点1\n                     -&gt; a                                            -- 展開する点2\n                     -&gt; (a -&gt; a)                                     -- 展開後の級数\ntwoPointTaylorSeries n f a b x = seriesA + seriesB\n  where\n  seriesA = (x - a) ^ n * sum (take n $ coefB |*| polyB)\n  seriesB = (x - b) ^ n * sum (take n $ coefA |*| polyA)\n  fa x = f x / (x - auto b)^n        -- A(x)\n  fb x = f x / (x - auto a)^n        -- B(x)\n  coefA = diffs fa a |/| factorials  -- A(a)/0!, A'(a)/1!, A''(a)/2!, A'''(a)/3!, ...\n  coefB = diffs fb b |/| factorials  -- B(b)/0!, B'(b)/1!, B''(b)/2!, B'''(b)/3!, ...\n  polyA = ((x - a)^) &lt;$&gt; [0..]       -- 1, x-a, (x-a)^2, (x-a)^3, ...\n  polyB = ((x - b)^) &lt;$&gt; [0..]       -- 1, x-b, (x-b)^2, (x-b)^3, ...\n  factorials = map (fromIntegral . fact) [0..] -- 0!, 1!, 2!, 3!, ...\n  (|/|) = zipWith (/)\n  (|*|) = zipWith (*)\n\n\ntwoPointTaylorSeries 2 id (-1) 1 (var \"x\") -- id ≡ f(x) = x\n\n0.25*(1.0+x)*(1.0+x)+(-0.25)*(-1.0+x)*(-1.0+x)\n\n\n式が複雑になるので\\(f(x)=x\\)という単純な関数を展開して確かめてみました。式を整理するとちゃんと正しい答えになってるのが分かります。\nそれでは実際に関数を近似してみましょう\nまずは\n\\[\n\\frac{1}{1+x^2}\n\\]\nという関数を展開してみましょう\n\nimport Graphics.Rendering.Chart.Easy\n\ncauchy :: Floating a =&gt; a -&gt; a\ncauchy x = 1 / (1 + x^2)\n\ndomain :: [Double]\ndomain = map (\\n -&gt; fromIntegral n / 100) [-100..100]\n\ntoRenderable $ do\n    plot (line \"cauchy\"    [flip map domain $ \\x -&gt; (x, cauchy x)])\n    plot (line \"one point\" [flip map domain $ \\x -&gt; (x, taylorSeries 5 cauchy 0 x)])\n    plot (line \"two point\" [flip map domain $ \\x -&gt; (x, twoPointTaylorSeries 5 cauchy (-1) 1 x)])\n\n\n\n\n\n\n\n\n青線が元の関数、緑線が\\(0\\)周りでの5次までのテイラー展開、赤線が\\(-1, 1\\)周りでの5次までの2点テイラー展開です。同じ次数までの展開ですが2点テイラー展開のほうがより高い精度で近似できているのが分かります\n次に区分的に定義された関数であるReLUを展開してみましょう\n\nrelu :: (Ord a, Floating a) =&gt; a -&gt; a\nrelu = max 0\n\ntoRenderable $ do\n    plot (line \"ReLU\"      [flip map domain $ \\x -&gt; (x, relu x)])\n    plot (line \"one point\" [flip map domain $ \\x -&gt; (x, taylorSeries 5 relu 1 x)])\n    plot (line \"two point\" [flip map domain $ \\x -&gt; (x, twoPointTaylorSeries 5 relu (-1) 1 x)])\n\n\n\n\n\n\n\n\nテイラー展開は\\(1\\)の周りで展開していますがやはり0以下で関数が変わっていることには対応できていません。一方で2点テイラー展開は\\(1\\)の周りに加えて\\(-1\\)の周りの情報もつかえているのでReLUの形をより正確に近似できているのが分かります。"
  },
  {
    "objectID": "posts/2020-07-09/index.html#参考文献",
    "href": "posts/2020-07-09/index.html#参考文献",
    "title": "2点テイラー展開の定義と数値実験",
    "section": "参考文献",
    "text": "参考文献\n\n[1] Estes, R. H., and E. R. Lancaster. “Two-point Taylor series expansions.” (1966).\n[2] Kitahara, Kazuaki, Taizo Chiyonobu, and Hirokazu Tsukamoto. “A note on two point Taylor expansion.” International Journal of Pure and Applied Mathematics 75.3 (2012): 327-338.\n[3] 鈴木 実, “エルミート補間の一般公式（Generalized Hermite interpolation）” http://totoha.web.fc2.com/Hermite_interpolation.pdf\n[4] https://twitter.com/KS_Mathematics/status/1279807348391854080"
  },
  {
    "objectID": "posts/2024-03-23/index.html",
    "href": "posts/2024-03-23/index.html",
    "title": "Haskellで実装するk-means法とk-means++法",
    "section": "",
    "text": "k-means問題はクラスタリングに関する問題で、データの集合を\\(X\\)、クラスタ数を\\(k\\)とした時に、\\(X\\)の分割\\(S = \\{S_1, S_2, \\dots, S_k\\}\\) の中で以下のコスト関数\n\\[\n\\underset{S}{\\arg\\min} \\sum_{i=1}^k\\sum_{x\\in S_i}\\|x-\\mu_i\\|^2\n\\]\nを最小にするものを見つけることが目的です。\nここで \\(\\mu_i\\) はクラスタの中心で\n\\[\n\\mu_i = \\frac{1}{|S_i|}\\sum_{x\\in S_i}x\n\\]\nと平均値で計算されることが多いです。\n\nk-means法\nこの問題はNP困難であることが知られていますが、k-means法（Lloydアルゴリズム）と呼ばれる局所解を高速に与える有名なアルゴリズムがあります。それは以下のようなものです。\n\nクラスタの中心としてデータ点からランダムにk個を選ぶ\n各データ点を中心が最も近いクラスタに分類する\n各クラスタに属するデータから改めて中心を計算する\n収束するまで2,3を繰り返す\n\nアルゴリズムのイメージは実際に視覚的に見てみるのが分かりやすいでしょう。以下のサイトがk-means法を可視化してくれていてインタラクティブに試すことができるのでオススメです。\n\nK-means 法を D3.js でビジュアライズしてみた\n\nHaskellにもk-means法を実装したライブラリはあります。\n\nkmeans\nkmeans-vector\nclustering\n\nですが今回は自分で実装します。\n\n{-# LANGUAGE BlockArguments, DataKinds #-} \n\nimport GHC.TypeLits\n\nimport qualified Data.Vector.Sized as V\n\n\n-- | ボロノイ分割\nvoronoiDecompose :: (KnownNat (n+1), Ord b)\n                 =&gt; (a -&gt; a -&gt; b)       -- 距離関数\n                 -&gt; [a]                 -- データ点\n                 -&gt; V.Vector (n+1) a    -- 中心点\n                 -&gt; V.Vector (n+1) [a]  -- ボロノイ分割\nvoronoiDecompose distance ds cs =\n  V.accum (flip (:)) (V.replicate []) $\n    map (\\d -&gt; (V.minIndex $ V.map (distance d) cs, d)) ds\n\n\n-- | k-means法\nkMeans :: (KnownNat (n+1), Eq a, Ord b)\n       =&gt; (a -&gt; a -&gt; b)     -- 距離関数\n       -&gt; ([a] -&gt; a)        -- 集約関数\n       -&gt; [a]               -- データ点\n       -&gt; V.Vector (n+1) a  -- 中心点\n       -&gt; V.Vector (n+1) a  -- 中心点\nkMeans distance aggregate ds cs =\n  let cs' = V.map aggregate $ voronoiDecompose distance ds cs\n   in if cs == cs' then cs' else kMeans distance aggregate ds cs'\n\nvoronoiDecompose は与えられた中心点に従ってデータ点をボロノイ領域で分類する関数です。データ点はリストとして扱っていますが、中心点はランダムアクセスしたいので Vector を使って \\(O(1)\\) アクセスできるようにしています。データ点の型は型変数で抽象化しており、必要になる距離関数は後から与えられるようになっています。\nkMeans はk-means法を計算する関数です。データ点をボロノイ分割した結果を集約して計算した新しい中心点がもとの中心点と一致するまで計算を繰り返します。\n\n\nk-means++法\nkMeans は中心点を更新していく関数として実装していますがそもそもの中心点はどのように用意すれば良いでしょうか。もちろんランダムなデータ点を取ってきても良いのですが、k-means++法と呼ばれる効率の良い中心点の与え方が知られています。k-means++法は以下のようなアルゴリズムです。\n\nデータ点からランダムに1つ目の中心点を選ぶ\nそれぞれのデータ点\\(x\\)に対して、最も近い中心点からの距離\\(D(x)\\)を計算する\nデータ点\\(x\\)につき重み\\(\\frac{D^2(x)}{\\sum_{x\\in X}D^2(x)}\\)を考慮して新しい中心点をランダムに選ぶ\n選ばれた中心点の数が予め与えられたクラスタ数\\(k\\)に到達するまで2,3を繰り返す\n\n感覚的には今ある中心点より遠くにあるデータ点が選ばれやすくなるように新しい中心点を選ぶような形になっています。それなら単純に\\(D(x)\\)に比例した重みでサンプリングしても良さそうなものですが、このアルゴリズムによって選ばれた中心点により評価したk-means問題のコスト関数の値を\\(\\phi\\)とすると、コスト関数の最小値\\(\\phi_{\\rm OPT}\\)に対して\n\\[\n{\\rm E}[\\phi] \\leq 8(\\log k+2)\\phi_{\\rm OPT}\n\\]\nを満たすことが証明できます。この証明にはコーシー・シュワルツの不等式が使われていて二乗の形であることが本質的な役割を果たしているのです（もう少し荒い評価にはなりますが単純に\\(l^p\\)距離を用いた場合の不等式も論文には載っています）。このようにk-means++法は初期の中心点を決めた時点で期待値における理論的な精度評価が得られていますが、更にその後k-means法を用いてコスト関数を単調減少させることにより良いクラスタリングの結果が得られるようになっているのです。\nそれではk-means++法を実装してみましょう。\n\nimport Data.Proxy (Proxy(..))\n\nimport qualified Data.Vector.Generic as VG\nimport qualified Data.Vector.Generic.Sized.Internal as VGSI\nimport Data.Random (randomElement, RVar)\nimport Data.Random.Distribution.Categorical (weightedCategorical)\n\n\n-- ref. https://github.com/expipiplus1/vector-sized/issues/123\nunfoldrM :: forall m n a b. (Monad m, KnownNat n)\n         =&gt; (b -&gt; m (a, b)) -&gt; b -&gt; m (V.Vector n a)\nunfoldrM f z = VGSI.Vector &lt;$&gt; VG.unfoldrExactNM i f z\n  where i = fromIntegral (natVal (Proxy :: Proxy n))\n\n\n-- | k-means++法\nkMeansPlusPlus :: KnownNat n\n               =&gt; (a -&gt; a -&gt; Double)  -- 距離関数\n               -&gt; [a]                 -- データ点\n               -&gt; RVar (V.Vector n a) -- 中心点\nkMeansPlusPlus distance ds = unfoldrM f []\n  where\n  f [] = do\n    c &lt;- randomElement ds\n    pure (c, [c])\n  f cs = do\n    let ws = map (\\d -&gt; minimum $ map (\\c -&gt; distance c d ^2) cs) ds\n    c &lt;- weightedCategorical (zip ws ds)\n    pure (c, c:cs)\n\nk-means++法を実装するためにunfoldrMという便利関数を定義しています。実はvectorライブラリにはこのような関数が定義されているのですがvector-sizedには無いので自前で実装しています（実装して欲しいというissueはあります）。\nunfoldrMを使えばk-means++法は素直に場合分けして実装するだけです。k-means++法はランダムな選択を伴うので何らかのモナドに包む必要があります。IOにしてしまっても良いのですが確率分布もまたそれ自体がモナドになるので、できるだけ抽象的な型に留める形で実装しています。確率分布（確率変数）の型として、ここでは random-fuのRVarを使っています。\n\n\n実験\nそれでは実装したk-means法、k-means++法を使って実際にクラスタリングを行ってみましょう。まずはクラスタリングの対象となる平面上の点を実装していきます。\n\nimport Data.List (foldl')\nimport Data.Maybe (fromJust)\n\n\n-- | 平面上の点\ntype Point = V.Vector 2 Double\n\n\n-- | x, y 座標から点を構築する\nmkPoint :: Double -&gt; Double -&gt; Point\nmkPoint a b = fromJust $ V.fromList [a, b]\n\n\n-- | 距離関数\ndistance :: Point -&gt; Point -&gt; Double\ndistance v1 v2 = sqrt . V.sum . V.map (^2) $ V.zipWith (-) v1 v2\n\n\n-- | 平均値関数\naverage :: [Point] -&gt; Point\naverage ps =\n  let n = fromIntegral $ length ps\n   in V.map (/n) $ foldl' (V.zipWith (+)) (V.replicate 0) ps\n\n最後にこれらの点をランダムにサンプリングしてクラスタリングしてみましょう。クラスタの数は型に現れるので型注釈で与えます。\n\nimport Control.Monad (replicateM)\nimport Data.Traversable (forM)\n\nimport Data.Random (normal, sampleFrom)\nimport Graphics.Rendering.Chart.Easy\nimport System.Random.Stateful (newIOGenM, mkStdGen)\n\n\nsamples :: RVar [Point]\nsamples = concat &lt;$&gt; forM clusters \\(m, s) -&gt;\n  replicateM nEachSamples $ mkPoint &lt;$&gt; normal m s &lt;*&gt; normal m s\n  where\n  nEachSamples = 100  \n  clusters = [(-2, 1), (4, 2)]\n\n\ndo\n  gen &lt;- newIOGenM (mkStdGen 42)\n  ds &lt;- sampleFrom gen samples\n  cs &lt;- sampleFrom gen $\n    kMeansPlusPlus distance ds :: IO (V.Vector 2 Point)  -- k-means++法\n  let cs' = kMeans distance average ds cs  -- k-means法\n      voronoi = voronoiDecompose distance ds cs'\n      toTuple v = (V.index v 0, V.index v 1)\n  pure $ toRenderable $ do\n    plot (points \"Group 1\" . map toTuple $ V.index voronoi 0)\n    plot (points \"Group 2\" . map toTuple $ V.index voronoi 1)"
  },
  {
    "objectID": "posts/2020-04-12/index.html",
    "href": "posts/2020-04-12/index.html",
    "title": "GHCi の :sprint が便利",
    "section": "",
    "text": "これは『Haskellによる並列・並行プログラミング』リモート輪講 #1で学んだことのメモです。\n:sprintは変数の評価を”行わずに”その内容を表示する機能。これを使えばサンクのまま詰まれていてまだ評価されていない部分も確認することができる\n\nlet x = 1 + 2 :: Int\n\n:sprint x\n\nx = _\n\n\n\n↑アンダースコアはサンクを表しておりxがまだ評価されていないことが分かる\n\nx\n\n:sprint x\n\n3\n\n\nx = 3\n\n\n\n↑xが評価されたので中身も見えるようになった\n次は変数が変数を参照している例\n\nx = 1 + 2 :: Int\ny = x + 1\n\n:sprint x\n:sprint y\n\nx = _\n\n\n\ny = _\n\n\n\n\nseq y ()\n\n:sprint x\n:sprint y\n\n()\n\n\nx = 3\n\n\n\ny = 4\n\n\n\n↑seqを使うと第一引数が弱頭部正規形（最初の構成子が見えるところ）まで強制的に評価される\n\nx = 1 + 2 :: Int\nz = (x, x)\n\n:sprint z\n\nz = _\n\n\n\nあれ？これはへいへいHaskellでは z = (_, _) と見えるはずなんだけど違う結果になってしまった。\n\nimport Data.Tuple\n\nz = swap (x, x + 1)\n\n:sprint z\n\nz = _\n\n\n\n\nseq z ()\n\n:sprint z\n\n()\n\n\nz = (_,_)\n\n\n\n↑今度はうまくタプルの構成子が見えるところまで評価された\n\nseq x ()\n\n:sprint z\n\n()\n\n\nz = (_,3)\n\n\n\n↑xだけ評価すると3が見えるようになった。zが評価されていないのでx + 1の部分はサンク_のままである\n今度はリストと map を使ったときの挙動を見てみる\n\nxs = map (+1) [1..10] :: [Int]\n\n:sprint xs\n\nxs = _\n\n\n\n\nseq xs ()\n\n:sprint xs\n\n()\n\n\nxs = _ : _\n\n\n\n↑:はリストの構成子なのでここが弱頭部正規形\n\nlength xs\n\n:sprint xs\n\n10\n\n\nxs = [_,_,_,_,_,_,_,_,_,_]\n\n\n\n↑lengthは中身を評価しないので構造だけが評価されて中はサンクのまま\n\nsum xs\n\n:sprint xs\n\n65\n\n\nxs = [2,3,4,5,6,7,8,9,10,11]\n\n\n\n↑これで全部評価された\n:sprint を使うとHaskellの遅延評価で何がどこまで評価されるのかインタラクティブに分かるので面白い。"
  },
  {
    "objectID": "posts/2020-03-29/index.html",
    "href": "posts/2020-03-29/index.html",
    "title": "高速フーリエ変換を実装してみた",
    "section": "",
    "text": "高速フーリエ変換の実装を難しそうかなと思っている方が、なんだ簡単じゃないですか！！ となるための実装講座です という記事が分かりやすかったのでHaskellでも実装してみました"
  },
  {
    "objectID": "posts/2020-03-29/index.html#離散フーリエ変換",
    "href": "posts/2020-03-29/index.html#離散フーリエ変換",
    "title": "高速フーリエ変換を実装してみた",
    "section": "離散フーリエ変換",
    "text": "離散フーリエ変換\nまずは普通のフーリエ変換を実装します\n\nimport Data.Complex\n\nfourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\nfourierTransform xs =\n  let n = length xs\n      f aj i j = aj * cis (2 * pi * fromIntegral (i * j) / fromIntegral n)\n   in flip map [0..n-1] $ \\i -&gt; foldr (\\(j, aj) -&gt; (+) (f aj i j)) 0 (zip [0..] xs)\n\ninverseFourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\ninverseFourierTransform xs =\n  let n = length xs\n      f aj i j = aj * cis (-2 * pi * fromIntegral (i * j) / fromIntegral n)\n   in flip map [0..n-1] $ \\i -&gt; foldr (\\(j, aj) -&gt; (+) (f aj i j)) 0 (zip [0..] xs) / fromIntegral n\n\n元に戻ることを確認。これは気が向いたらQuickCheckで書き直したい\n\ninverseFourierTransform $ fourierTransform [1, 2, 3, 4]\n\n[1.0000000000000002 :+ 5.551115123125783e-16,2.0 :+ 3.885780586188048e-16,3.0 :+ 5.551115123125783e-17,4.0 :+ (-3.3306690738754696e-16)]"
  },
  {
    "objectID": "posts/2020-03-29/index.html#高速フーリエ変換",
    "href": "posts/2020-03-29/index.html#高速フーリエ変換",
    "title": "高速フーリエ変換を実装してみた",
    "section": "高速フーリエ変換",
    "text": "高速フーリエ変換\n高速フーリエ変換はフーリエ変換の計算を分割して再帰的に計算するので関数型プログラミングと相性が良さそうかなと思ったけど実装は泥臭い感じになりました。うまいやり方とかあったらTwitterでこっそり教えて下さい\nあと単純な実装なので2の累乗の長さのリストでしかうまく行かないやつです。\n\nimport Control.Arrow\n\nsplitEvenOdd :: [a] -&gt; ([a], [a])\nsplitEvenOdd = (reverse *** reverse) . go ([], [])\n  where go x [] = x\n        go (xs, ys) [x] = (x:xs, ys)\n        go (xs, ys) (x:y:zs) = go (x:xs, y:ys) zs\n\nmapTuple2 :: (a -&gt; b) -&gt; (a, a) -&gt; (b, b)\nmapTuple2 f (a1, a2) = (f a1, f a2)\n\nfastFourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\nfastFourierTransform []  = error \"The length of list must be the power of 2.\"\nfastFourierTransform [x] = [x]\nfastFourierTransform xs  =\n  let n = length xs\n      (bs, cs) = mapTuple2 fastFourierTransform $ splitEvenOdd xs\n      atN2 xs i = xs !! (i `mod` (n `div` 2))\n      f i = bs `atN2` i + cs `atN2` i * cis (2 * pi * fromIntegral i / fromIntegral n)\n   in map f [0..n-1]\n\ninverseFastFourierTransform :: RealFloat a =&gt; [Complex a] -&gt; [Complex a]\ninverseFastFourierTransform xs = map (/ fromIntegral (length xs)) $ ifft xs\n  where\n    ifft []  = error \"The length of list must be the power of 2.\"\n    ifft [x] = [x]\n    ifft xs  =\n      let n = length xs\n          (bs, cs) = mapTuple2 ifft $ splitEvenOdd xs\n          atN2 xs i = xs !! (i `mod` (n `div` 2))\n          f i = bs `atN2` i + cs `atN2` i * cis (-2 * pi * fromIntegral i / fromIntegral n)\n       in map f [0..n-1]\n\nこれも元に戻ることを確認\n\ninverseFastFourierTransform $ fastFourierTransform [1,2,3,4]\n\n[1.0 :+ 4.057416247971343e-16,2.0 :+ 9.385873628418619e-17,3.0 :+ 8.411709486180696e-17,4.0 :+ (-2.1632341619892149e-16)]"
  },
  {
    "objectID": "posts/2020-03-29/index.html#実験ローパスフィルタ",
    "href": "posts/2020-03-29/index.html#実験ローパスフィルタ",
    "title": "高速フーリエ変換を実装してみた",
    "section": "実験：ローパスフィルタ",
    "text": "実験：ローパスフィルタ\n実装したFFTでうまく周波数の空間に変換できてるのか確認します。低周波と高周波を合成した信号を作成し、低周波成分だけ取り出してみます。\n\nimport Graphics.Rendering.Chart.Easy\n\nsignal :: [Double]\nsignal = map (\\i -&gt; sin (2 * pi * fromIntegral i / 32) + sin (2 * pi * fromIntegral i / 512)) [1..2048]\n\ntoRenderable $ plot (line \"sigmal\" [zip [0..] signal])\n\n\n\n\n\n\n\n\n実行した高速フーリエ変換で変換して周波数空間での様子を確認\n\nfSignal :: [Complex Double]\nfSignal = fastFourierTransform $ map (:+ 0) signal\n\nfSignalR, fSignalI :: [Double]\nfSignalR = map realPart fSignal\nfSignalI = map imagPart fSignal\n\ntoRenderable $ do\n    plot (line \"fSignalR\" [zip [0..] fSignalR])\n    plot (line \"fSignalI\" [zip [0..] fSignalI])\n\n\n\n\n\n\n\n\nローパスフィルタは、フーリエ変換して先頭からN個の成分以外を0にして逆フーリエ変換するように実装する\n想定通りに低周波成分だけ取り出すことができた。なんだ簡単じゃないですか！！\n\nconsider :: Num a =&gt; Int -&gt; [a] -&gt; [a]\nconsider _ []     = []\nconsider 0 xs     = replicate (length xs) 0\nconsider n (x:xs) = x : consider (n-1) xs\n\nlowPassFilter :: Int -&gt; [Double] -&gt; [Double]\nlowPassFilter n = map realPart . inverseFastFourierTransform . consider n . fastFourierTransform . map (:+ 0)\n\nsignal' :: [Double]\nsignal' = lowPassFilter 10 signal\n\ntoRenderable $ plot (line \"signal'\" [zip [0..] signal'])\n\n\n\n\n\n\n\n\n高速フーリエ変換、完全に理解した。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "HaskellでQR分解を実装する\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2024\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nHaskellで実装するk-means法とk-means++法\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2024\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\n高次元空間ではL1距離を使うのが良さそう\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\n2点テイラー展開の定義と数値実験\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nHaskellの非同期処理を使った入出力の重ね合わせ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJun 29, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\nGHCi の :sprint が便利\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2020\n\n\nlotz\n\n\n\n\n\n\n\n\n\n\n\n\n高速フーリエ変換を実装してみた\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2020\n\n\nlotz\n\n\n\n\n\n\nNo matching items"
  }
]